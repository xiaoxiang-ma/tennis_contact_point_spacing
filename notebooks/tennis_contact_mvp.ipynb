{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tennis Contact Point Analysis\n",
    "\n",
    "Upload a **video** of your tennis rally to automatically detect contact frames and analyze body positioning.\n",
    "\n",
    "**How it works:**\n",
    "1. **TrackNet** (deep learning) tracks the ball throughout the video\n",
    "2. **Audio analysis** detects impact sounds (ball hitting racket)\n",
    "3. Both signals are **fused** for robust contact detection\n",
    "4. For each contact, we analyze pose and measure contact point spacing\n",
    "\n",
    "**Steps:**\n",
    "1. Run the **Setup** cell to install dependencies\n",
    "2. Run the **Upload & Analyze** cell - upload your video\n",
    "3. View detected contacts and select which to analyze in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Setup - Install dependencies and clone repo\n",
    "import os, sys, shutil\n",
    "\n",
    "REPO_URL = \"https://github.com/xiaoxiang-ma/tennis_contact_point_spacing.git\"\n",
    "REPO_DIR = \"/content/tennis_contact_point_spacing\"\n",
    "\n",
    "# Always re-clone to ensure latest code\n",
    "if os.path.exists(REPO_DIR):\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "!git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "!pip install -q -r {REPO_DIR}/requirements.txt\n",
    "\n",
    "# Clear any cached module imports from previous runs\n",
    "for mod_name in list(sys.modules.keys()):\n",
    "    if mod_name.startswith((\"src.\", \"utils.\")):\n",
    "        del sys.modules[mod_name]\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "# Create weights directory\n",
    "os.makedirs(os.path.join(REPO_DIR, \"weights\"), exist_ok=True)\n",
    "\n",
    "print(\"\\nSetup complete!\")\n",
    "print(\"Note: TrackNet weights will be downloaded automatically on first use (~50MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Upload Video & Detect Contacts\nimport numpy as np\nimport cv2\nfrom google.colab import files\nfrom IPython.display import display, Image as IPImage, HTML\nimport os\n\nfrom utils.video_io import load_video\nfrom src.tracknet import TrackNetDetector\nfrom src.contact_detection import detect_contacts, get_contact_ball_position\n\n#@markdown ### Settings\nSHOT_TYPE = \"right_forehand\"  #@param [\"right_forehand\", \"right_backhand\", \"left_forehand\", \"left_backhand\"]\nUSE_AUDIO = True  #@param {type:\"boolean\"}\nDEBUG_MODE = True  #@param {type:\"boolean\"}\nSAVE_DEBUG_FRAMES = True  #@param {type:\"boolean\"}\n\n# Create output directory\noutput_dir = \"/content/output\"\nos.makedirs(output_dir, exist_ok=True)\n\n# --- Upload video ---\nprint(\"Upload your tennis video (MP4, MOV, etc.):\")\nuploaded = files.upload()\nvideo_filename = list(uploaded.keys())[0]\nvideo_path = os.path.join(\"/content\", video_filename)\nwith open(video_path, \"wb\") as f:\n    f.write(uploaded[video_filename])\n\n# --- Load video ---\nprint(f\"\\nLoading video: {video_filename}\")\nframes, metadata = load_video(video_path)\nfps = metadata[\"fps\"]\nprint(f\"  Resolution: {metadata['width']}x{metadata['height']}\")\nprint(f\"  Frame rate: {fps:.1f} fps\")\nprint(f\"  Duration: {metadata['duration_sec']:.2f}s ({len(frames)} frames)\")\n\n# --- Initialize TrackNet ---\nprint(\"\\nInitializing TrackNet (downloading weights if needed)...\")\ntracknet = TrackNetDetector(\n    weights_path=None,  # Auto-download\n    device=None,  # Auto-detect GPU/CPU\n    confidence_threshold=0.5,\n    save_debug_frames=SAVE_DEBUG_FRAMES,\n    debug_output_dir=os.path.join(output_dir, \"tracknet_debug\"),\n)\n\n# Check if weights loaded successfully\nif not tracknet.weights_loaded:\n    print(\"\\n\" + \"!\"*60)\n    print(\"WARNING: TrackNet weights failed to load!\")\n    print(\"Ball detection will NOT work properly.\")\n    print(\"Check the error message above for details.\")\n    print(\"!\"*60 + \"\\n\")\n\n# --- Detect contacts ---\nprint(\"\\nDetecting contacts (this may take a few minutes)...\")\ncontacts, ball_detections = detect_contacts(\n    video_path=video_path,\n    frames=frames,\n    fps=fps,\n    tracknet_detector=tracknet,\n    use_audio=USE_AUDIO,\n    debug=DEBUG_MODE,\n    save_debug_frames=SAVE_DEBUG_FRAMES,\n)\n\n# --- Display results ---\nprint(f\"\\n\" + \"=\"*60)\nprint(f\"CONTACT DETECTION RESULTS\")\nprint(f\"=\"*60)\nprint(f\"Ball detected in {len(ball_detections)}/{len(frames)} frames ({100*len(ball_detections)/len(frames):.1f}%)\")\n\n# Show sample debug frames if available\nif SAVE_DEBUG_FRAMES:\n    debug_dir = os.path.join(output_dir, \"tracknet_debug\")\n    import glob\n    debug_frames = sorted(glob.glob(os.path.join(debug_dir, \"frame_*.png\")))[:3]\n    if debug_frames:\n        print(f\"\\nSample TrackNet debug frames (from {debug_dir}):\")\n        for df in debug_frames:\n            print(f\"  - {os.path.basename(df)}\")\n            display(IPImage(filename=df, width=800))\n\nprint(f\"\\nDetected {len(contacts)} contact(s):\")\nprint()\n\n# Store contact info for later use\ncontact_info = []\nfor i, (frame_num, confidence, source) in enumerate(contacts):\n    time_sec = frame_num / fps\n    \n    # Get ball position at this contact\n    ball_pos, ball_method = get_contact_ball_position(frame_num, ball_detections)\n    \n    contact_info.append({\n        'index': i,\n        'frame': frame_num,\n        'time': time_sec,\n        'confidence': confidence,\n        'source': source,\n        'ball_pos': ball_pos,\n        'ball_method': ball_method,\n    })\n    \n    print(f\"  Contact {i+1}: Frame {frame_num} ({time_sec:.2f}s)\")\n    print(f\"    Confidence: {confidence:.0%} (source: {source})\")\n    if ball_pos:\n        print(f\"    Ball position: ({ball_pos[0]:.0f}, {ball_pos[1]:.0f}) [{ball_method}]\")\n    else:\n        print(f\"    Ball position: Not available\")\n    print()\n\n# Store for next cell\nANALYSIS_DATA = {\n    'frames': frames,\n    'fps': fps,\n    'metadata': metadata,\n    'contacts': contact_info,\n    'ball_detections': ball_detections,\n    'shot_type': SHOT_TYPE,\n    'video_path': video_path,\n}\n\nif len(contacts) > 0:\n    print(\"\\nRun the next cell to analyze a specific contact in detail.\")\nelse:\n    print(\"\\nNo contacts detected. Check the debug frames above to see what TrackNet is detecting.\")\n    print(\"You can also run the Debug cell at the bottom to see more details.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Analyze Selected Contact\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from IPython.display import display, Image as IPImage\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "\n",
    "from utils.coordinate_transforms import (\n",
    "    pelvis_origin_transform, estimate_ground_plane, apply_ground_plane\n",
    ")\n",
    "from src.pose_estimation import PoseEstimator\n",
    "from src.measurements import compute_measurements\n",
    "from src.visualization import (\n",
    "    draw_skeleton, draw_contact_point, save_annotated_frame\n",
    ")\n",
    "\n",
    "#@markdown ### Select which contact to analyze:\n",
    "CONTACT_INDEX = 0  #@param {type:\"integer\"}\n",
    "\n",
    "# Validate\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first to detect contacts!\")\n",
    "\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "if len(contacts) == 0:\n",
    "    raise ValueError(\"No contacts were detected in the video.\")\n",
    "\n",
    "if CONTACT_INDEX < 0 or CONTACT_INDEX >= len(contacts):\n",
    "    raise ValueError(f\"Invalid contact index. Valid range: 0-{len(contacts)-1}\")\n",
    "\n",
    "contact = contacts[CONTACT_INDEX]\n",
    "frame_num = contact['frame']\n",
    "ball_pos = contact['ball_pos']\n",
    "ball_method = contact['ball_method']\n",
    "shot_type = ANALYSIS_DATA['shot_type']\n",
    "frames = ANALYSIS_DATA['frames']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "\n",
    "print(f\"Analyzing Contact {CONTACT_INDEX + 1}\")\n",
    "print(f\"  Frame: {frame_num} ({contact['time']:.2f}s)\")\n",
    "print(f\"  Detection confidence: {contact['confidence']:.0%}\")\n",
    "print(f\"  Ball position method: {ball_method}\")\n",
    "\n",
    "# Get frame\n",
    "frame = frames[frame_num]\n",
    "h, w = frame.shape[:2]\n",
    "\n",
    "# Determine which wrist to use based on shot type\n",
    "if shot_type in [\"right_forehand\", \"right_backhand\"]:\n",
    "    contact_wrist_name = \"right_wrist\"\n",
    "    hand_label = \"RIGHT\"\n",
    "else:\n",
    "    contact_wrist_name = \"left_wrist\"\n",
    "    hand_label = \"LEFT\"\n",
    "\n",
    "# --- Pose estimation ---\n",
    "print(\"\\nEstimating pose...\")\n",
    "pose_estimator = PoseEstimator(static_image_mode=True, model_complexity=2)\n",
    "landmarks, raw_result = pose_estimator.process_frame(frame)\n",
    "\n",
    "if landmarks is None:\n",
    "    pose_estimator.close()\n",
    "    raise ValueError(\"No pose detected in frame. The player may not be clearly visible.\")\n",
    "\n",
    "pixel_lm = pose_estimator.get_pixel_landmarks(raw_result, frame.shape)\n",
    "pose_estimator.close()\n",
    "print(\"  Pose detected successfully!\")\n",
    "\n",
    "# --- Get contact point (ball position or fallback to wrist) ---\n",
    "if ball_pos is not None:\n",
    "    contact_pixel = ball_pos\n",
    "    contact_source = f\"ball ({ball_method})\"\n",
    "    print(f\"  Using ball position as contact point: ({ball_pos[0]:.0f}, {ball_pos[1]:.0f})\")\n",
    "else:\n",
    "    # Fallback to wrist\n",
    "    if contact_wrist_name in pixel_lm:\n",
    "        contact_pixel = pixel_lm[contact_wrist_name]\n",
    "        contact_source = \"wrist (fallback)\"\n",
    "        print(f\"  Ball not detected - using wrist position as fallback\")\n",
    "    else:\n",
    "        raise ValueError(\"Neither ball nor wrist position available\")\n",
    "\n",
    "# --- Transform coordinates for measurements ---\n",
    "pelvis = landmarks.get(\"pelvis\", np.zeros(3))\n",
    "centered = pelvis_origin_transform(landmarks)\n",
    "ground_z = estimate_ground_plane(centered)\n",
    "adjusted = apply_ground_plane(centered, ground_z)\n",
    "\n",
    "# For contact point, we need to estimate 3D position from 2D ball detection\n",
    "# Use wrist depth as approximation (ball is near wrist at contact)\n",
    "wrist_3d = landmarks.get(contact_wrist_name, np.zeros(3))\n",
    "contact_3d = wrist_3d.copy()  # Start with wrist position\n",
    "\n",
    "# If we have ball pixel position, adjust x/y based on pixel offset from wrist\n",
    "if ball_pos is not None and contact_wrist_name in pixel_lm:\n",
    "    wrist_px = pixel_lm[contact_wrist_name]\n",
    "    # Estimate scale from wrist (pixels to normalized coords)\n",
    "    # This is approximate - proper depth estimation would need stereo or depth camera\n",
    "    px_offset_x = ball_pos[0] - wrist_px[0]\n",
    "    px_offset_y = ball_pos[1] - wrist_px[1]\n",
    "    \n",
    "    # Rough scaling (assume ~1000px corresponds to ~1 normalized unit)\n",
    "    scale = 0.001  \n",
    "    contact_3d[0] += px_offset_x * scale\n",
    "    contact_3d[1] += px_offset_y * scale\n",
    "\n",
    "contact_adjusted = contact_3d - pelvis - np.array([0, 0, ground_z])\n",
    "\n",
    "# --- Compute measurements ---\n",
    "print(\"Computing measurements...\")\n",
    "meas = compute_measurements(adjusted, contact_adjusted)\n",
    "meas[\"contact_source\"] = contact_source\n",
    "meas[\"ball_detection_method\"] = ball_method\n",
    "meas[\"shot_type\"] = shot_type\n",
    "meas[\"frame_num\"] = frame_num\n",
    "meas[\"contact_confidence\"] = contact['confidence']\n",
    "\n",
    "# --- Create output directory ---\n",
    "output_dir = \"/content/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- 1. Annotated frame with skeleton + contact point ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONTACT FRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "annotated = frame.copy()\n",
    "annotated = draw_skeleton(annotated, pixel_lm, thickness=3)\n",
    "\n",
    "# Draw contact point (ball position or wrist)\n",
    "cx, cy = int(contact_pixel[0]), int(contact_pixel[1])\n",
    "draw_contact_point(annotated, cx, cy, radius=15)\n",
    "\n",
    "# Add label\n",
    "label = f\"CONTACT ({contact_source})\"\n",
    "cv2.putText(annotated, label, (cx + 20, cy - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "# Add frame info\n",
    "info_text = f\"Frame {frame_num} | {contact['time']:.2f}s | Conf: {contact['confidence']:.0%}\"\n",
    "cv2.putText(annotated, info_text, (20, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "out_path = os.path.join(output_dir, f\"contact_{CONTACT_INDEX+1}_frame_{frame_num}.png\")\n",
    "save_annotated_frame(annotated, out_path)\n",
    "\n",
    "print(\"\\nAnnotated contact frame:\")\n",
    "display(IPImage(filename=out_path, width=800))\n",
    "\n",
    "# --- 2. Ball trajectory visualization ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BALL TRAJECTORY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ball_detections = ANALYSIS_DATA['ball_detections']\n",
    "if ball_detections:\n",
    "    traj_frame = frame.copy()\n",
    "    \n",
    "    # Draw ball trajectory\n",
    "    sorted_frames = sorted(ball_detections.keys())\n",
    "    points = [(int(ball_detections[f][0]), int(ball_detections[f][1])) for f in sorted_frames]\n",
    "    \n",
    "    # Draw trajectory line\n",
    "    for i in range(1, len(points)):\n",
    "        # Color gradient: blue (old) -> green (new)\n",
    "        t = i / len(points)\n",
    "        color = (int(255*(1-t)), int(255*t), 0)\n",
    "        cv2.line(traj_frame, points[i-1], points[i], color, 2)\n",
    "    \n",
    "    # Draw ball positions as dots\n",
    "    for f in sorted_frames:\n",
    "        x, y, conf = ball_detections[f]\n",
    "        color = (0, 255, 0) if f != frame_num else (0, 0, 255)\n",
    "        cv2.circle(traj_frame, (int(x), int(y)), 4, color, -1)\n",
    "    \n",
    "    # Highlight contact frame ball position\n",
    "    if ball_pos:\n",
    "        cv2.circle(traj_frame, (int(ball_pos[0]), int(ball_pos[1])), 12, (0, 0, 255), 3)\n",
    "        cv2.putText(traj_frame, \"CONTACT\", (int(ball_pos[0])+15, int(ball_pos[1])-5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    \n",
    "    traj_path = os.path.join(output_dir, f\"trajectory_{CONTACT_INDEX+1}.png\")\n",
    "    cv2.imwrite(traj_path, traj_frame)\n",
    "    display(IPImage(filename=traj_path, width=800))\n",
    "else:\n",
    "    print(\"No ball trajectory data available.\")\n",
    "\n",
    "# --- 3. Measurements ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONTACT POINT MEASUREMENTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nShot type: {shot_type}\")\n",
    "print(f\"Contact source: {contact_source}\")\n",
    "print()\n",
    "print(f\"Lateral offset:      {meas.get('lateral_offset_cm', 0):>7.1f} cm  ({meas.get('lateral_offset_inches', 0):>5.1f} in)\")\n",
    "print(f\"  (+ = to your left, - = to your right)\")\n",
    "print(f\"Forward/back:        {meas.get('forward_back_cm', 0):>7.1f} cm  ({meas.get('forward_back_inches', 0):>5.1f} in)\")\n",
    "print(f\"  (+ = in front, - = behind)\")\n",
    "print(f\"Height above ground: {meas.get('height_above_ground_cm', 0):>7.1f} cm  ({meas.get('height_above_ground_inches', 0):>5.1f} in)\")\n",
    "if \"shoulder_line_distance_cm\" in meas:\n",
    "    print(f\"Shoulder line dist:  {meas.get('shoulder_line_distance_cm', 0):>7.1f} cm  ({meas.get('shoulder_line_distance_inches', 0):>5.1f} in)\")\n",
    "if \"relative_to_shoulder_height_cm\" in meas:\n",
    "    print(f\"vs Shoulder height:  {meas.get('relative_to_shoulder_height_cm', 0):>7.1f} cm  ({meas.get('relative_to_shoulder_height_inches', 0):>5.1f} in)\")\n",
    "    print(f\"  (+ = above shoulder, - = below)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save measurements CSV\n",
    "csv_path = os.path.join(output_dir, f\"measurements_contact_{CONTACT_INDEX+1}.csv\")\n",
    "df = pd.DataFrame([meas])\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nMeasurements saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Analyze All Contacts (Batch)\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils.coordinate_transforms import (\n",
    "    pelvis_origin_transform, estimate_ground_plane, apply_ground_plane\n",
    ")\n",
    "from src.pose_estimation import PoseEstimator\n",
    "from src.measurements import compute_measurements\n",
    "\n",
    "#@markdown Run this cell to analyze ALL detected contacts at once.\n",
    "\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first!\")\n",
    "\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "frames = ANALYSIS_DATA['frames']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "shot_type = ANALYSIS_DATA['shot_type']\n",
    "ball_detections = ANALYSIS_DATA['ball_detections']\n",
    "\n",
    "if len(contacts) == 0:\n",
    "    print(\"No contacts to analyze.\")\n",
    "else:\n",
    "    print(f\"Analyzing {len(contacts)} contacts...\\n\")\n",
    "    \n",
    "    all_measurements = []\n",
    "    pose_estimator = PoseEstimator(static_image_mode=True, model_complexity=2)\n",
    "    \n",
    "    # Determine wrist based on shot type\n",
    "    if shot_type in [\"right_forehand\", \"right_backhand\"]:\n",
    "        contact_wrist_name = \"right_wrist\"\n",
    "    else:\n",
    "        contact_wrist_name = \"left_wrist\"\n",
    "    \n",
    "    for contact in contacts:\n",
    "        idx = contact['index']\n",
    "        frame_num = contact['frame']\n",
    "        ball_pos = contact['ball_pos']\n",
    "        ball_method = contact['ball_method']\n",
    "        \n",
    "        print(f\"Contact {idx+1}: Frame {frame_num}...\", end=\" \")\n",
    "        \n",
    "        frame = frames[frame_num]\n",
    "        landmarks, raw_result = pose_estimator.process_frame(frame)\n",
    "        \n",
    "        if landmarks is None:\n",
    "            print(\"SKIPPED (no pose detected)\")\n",
    "            continue\n",
    "        \n",
    "        pixel_lm = pose_estimator.get_pixel_landmarks(raw_result, frame.shape)\n",
    "        \n",
    "        # Get contact point\n",
    "        if ball_pos is not None:\n",
    "            contact_pixel = ball_pos\n",
    "            contact_source = f\"ball ({ball_method})\"\n",
    "        elif contact_wrist_name in pixel_lm:\n",
    "            contact_pixel = pixel_lm[contact_wrist_name]\n",
    "            contact_source = \"wrist (fallback)\"\n",
    "        else:\n",
    "            print(\"SKIPPED (no contact point)\")\n",
    "            continue\n",
    "        \n",
    "        # Transform and measure\n",
    "        pelvis = landmarks.get(\"pelvis\", np.zeros(3))\n",
    "        centered = pelvis_origin_transform(landmarks)\n",
    "        ground_z = estimate_ground_plane(centered)\n",
    "        adjusted = apply_ground_plane(centered, ground_z)\n",
    "        \n",
    "        wrist_3d = landmarks.get(contact_wrist_name, np.zeros(3))\n",
    "        contact_3d = wrist_3d.copy()\n",
    "        \n",
    "        if ball_pos is not None and contact_wrist_name in pixel_lm:\n",
    "            wrist_px = pixel_lm[contact_wrist_name]\n",
    "            px_offset_x = ball_pos[0] - wrist_px[0]\n",
    "            px_offset_y = ball_pos[1] - wrist_px[1]\n",
    "            scale = 0.001\n",
    "            contact_3d[0] += px_offset_x * scale\n",
    "            contact_3d[1] += px_offset_y * scale\n",
    "        \n",
    "        contact_adjusted = contact_3d - pelvis - np.array([0, 0, ground_z])\n",
    "        meas = compute_measurements(adjusted, contact_adjusted)\n",
    "        \n",
    "        meas[\"contact_index\"] = idx + 1\n",
    "        meas[\"frame_num\"] = frame_num\n",
    "        meas[\"time_sec\"] = contact['time']\n",
    "        meas[\"contact_confidence\"] = contact['confidence']\n",
    "        meas[\"contact_source\"] = contact_source\n",
    "        meas[\"detection_source\"] = contact['source']\n",
    "        meas[\"shot_type\"] = shot_type\n",
    "        \n",
    "        all_measurements.append(meas)\n",
    "        print(\"OK\")\n",
    "    \n",
    "    pose_estimator.close()\n",
    "    \n",
    "    # Save combined results\n",
    "    if all_measurements:\n",
    "        output_dir = \"/content/output\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        df = pd.DataFrame(all_measurements)\n",
    "        csv_path = os.path.join(output_dir, \"all_contacts_measurements.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"SUMMARY OF ALL CONTACTS\")\n",
    "        print(\"=\"*60)\n",
    "        display(df[['contact_index', 'frame_num', 'time_sec', 'contact_confidence', \n",
    "                    'lateral_offset_cm', 'forward_back_cm', 'height_above_ground_cm',\n",
    "                    'contact_source']])\n",
    "        \n",
    "        print(f\"\\nResults saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Download Results\n",
    "from google.colab import files as colab_files\n",
    "import glob\n",
    "\n",
    "output_dir = \"/content/output\"\n",
    "all_files = glob.glob(os.path.join(output_dir, \"*\"))\n",
    "\n",
    "print(\"Downloading files...\")\n",
    "for f in all_files:\n",
    "    print(f\"  {os.path.basename(f)}\")\n",
    "    colab_files.download(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Debug: View Ball Detection & Audio Analysis (Optional)\n",
    "\n",
    "Run the cell below to visualize TrackNet's ball detection and audio envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Debug: Ball Detection & Audio Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first!\")\n",
    "\n",
    "ball_detections = ANALYSIS_DATA['ball_detections']\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "num_frames = len(ANALYSIS_DATA['frames'])\n",
    "video_path = ANALYSIS_DATA['video_path']\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Ball detection confidence over time\n",
    "ax1 = axes[0]\n",
    "if ball_detections:\n",
    "    frames_detected = sorted(ball_detections.keys())\n",
    "    confidences = [ball_detections[f][2] for f in frames_detected]\n",
    "    times = [f/fps for f in frames_detected]\n",
    "    \n",
    "    ax1.plot(times, confidences, 'b-', alpha=0.7, label='Ball confidence')\n",
    "    ax1.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Threshold')\n",
    "    \n",
    "    # Mark contacts\n",
    "    for c in contacts:\n",
    "        ax1.axvline(x=c['time'], color='g', linestyle='-', alpha=0.8)\n",
    "        ax1.text(c['time'], 1.0, f\"C{c['index']+1}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Detection Confidence')\n",
    "ax1.set_title('TrackNet Ball Detection Confidence')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1.1)\n",
    "\n",
    "# Plot 2: Ball position (x, y) over time\n",
    "ax2 = axes[1]\n",
    "if ball_detections:\n",
    "    xs = [ball_detections[f][0] for f in frames_detected]\n",
    "    ys = [ball_detections[f][1] for f in frames_detected]\n",
    "    \n",
    "    ax2.plot(times, xs, 'r-', alpha=0.7, label='X position')\n",
    "    ax2.plot(times, ys, 'b-', alpha=0.7, label='Y position')\n",
    "    \n",
    "    for c in contacts:\n",
    "        ax2.axvline(x=c['time'], color='g', linestyle='-', alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_ylabel('Position (pixels)')\n",
    "ax2.set_title('Ball Position Over Time')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: Audio envelope (if available)\n",
    "ax3 = axes[2]\n",
    "try:\n",
    "    from src.audio_detection import get_audio_envelope_for_debug\n",
    "    audio, sr, envelope = get_audio_envelope_for_debug(video_path)\n",
    "    \n",
    "    audio_times = np.arange(len(envelope)) / sr\n",
    "    ax3.plot(audio_times, envelope, 'purple', alpha=0.7, label='Audio envelope (1-4kHz)')\n",
    "    \n",
    "    for c in contacts:\n",
    "        ax3.axvline(x=c['time'], color='g', linestyle='-', alpha=0.8)\n",
    "        ax3.text(c['time'], envelope.max(), f\"C{c['index']+1}\", ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    ax3.set_xlabel('Time (s)')\n",
    "    ax3.set_ylabel('Amplitude')\n",
    "    ax3.set_title('Audio Envelope (bandpass filtered for impact sounds)')\n",
    "    ax3.legend()\n",
    "except Exception as e:\n",
    "    ax3.text(0.5, 0.5, f'Audio analysis not available: {e}', \n",
    "             ha='center', va='center', transform=ax3.transAxes)\n",
    "    ax3.set_title('Audio Envelope (not available)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/output/detection_debug.png', dpi=120)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBall detected in {len(ball_detections)}/{num_frames} frames ({100*len(ball_detections)/num_frames:.1f}%)\")\n",
    "print(f\"Contacts detected: {len(contacts)}\")\n",
    "for c in contacts:\n",
    "    print(f\"  Contact {c['index']+1}: {c['time']:.2f}s (source: {c['source']}, conf: {c['confidence']:.0%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}