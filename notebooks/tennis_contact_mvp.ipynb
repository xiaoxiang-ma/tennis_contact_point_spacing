{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Tennis Contact Point Analysis - MVP\n\nUpload a **single image** of your contact moment to analyze body positioning and measure contact point spacing.\n\n**Steps:**\n1. Run the **Setup** cell to install dependencies\n2. Run the **Upload & Analyze** cell — upload your contact frame image\n3. View results: annotated image with skeleton overlay + measurements table"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 1. Setup - Install dependencies and clone repo\nimport os, sys, shutil\n\nREPO_URL = \"https://github.com/xiaoxiang-ma/tennis_contact_point_spacing.git\"\nREPO_DIR = \"/content/tennis_contact_point_spacing\"\n\n# Always re-clone to ensure latest code\nif os.path.exists(REPO_DIR):\n    shutil.rmtree(REPO_DIR)\n!git clone {REPO_URL} {REPO_DIR}\n\n!pip install -q -r {REPO_DIR}/requirements.txt\n\n# Clear any cached module imports from previous runs\nfor mod_name in list(sys.modules.keys()):\n    if mod_name.startswith((\"src.\", \"utils.\")):\n        del sys.modules[mod_name]\n\nif REPO_DIR not in sys.path:\n    sys.path.insert(0, REPO_DIR)\n\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Upload & Analyze Contact Frame\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom google.colab import files\nfrom IPython.display import display, Image as IPImage\nimport os\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom utils.coordinate_transforms import (\n    pelvis_origin_transform, estimate_ground_plane,\n    apply_ground_plane\n)\nfrom src.pose_estimation import PoseEstimator\nfrom src.measurements import compute_measurements\nfrom src.visualization import (\n    draw_skeleton, draw_contact_point, draw_measurements, save_annotated_frame\n)\n\n#@markdown ### Shot Type (select one):\nSHOT_TYPE = \"right_forehand\"  #@param [\"right_forehand\", \"right_backhand\", \"left_forehand\", \"left_backhand\"]\n\n# Determine which wrist to use based on shot type\nif SHOT_TYPE in [\"right_forehand\", \"right_backhand\"]:\n    contact_wrist_name = \"right_wrist\"\n    hand_label = \"RIGHT\"\nelse:\n    contact_wrist_name = \"left_wrist\"\n    hand_label = \"LEFT\"\n\nprint(f\"Shot type: {SHOT_TYPE} → using {hand_label} wrist as contact point\")\n\n# --- Upload image ---\nprint(\"\\nUpload your contact frame image (PNG, JPG):\")\nuploaded = files.upload()\nimage_filename = list(uploaded.keys())[0]\nimage_path = os.path.join(\"/content\", image_filename)\nwith open(image_path, \"wb\") as f:\n    f.write(uploaded[image_filename])\n\n# --- Load image ---\nprint(f\"\\nLoading image: {image_filename}\")\nframe = cv2.imread(image_path)\nif frame is None:\n    raise ValueError(f\"Could not load image: {image_path}\")\nh, w = frame.shape[:2]\nprint(f\"  Resolution: {w}x{h}\")\n\n# --- Pose estimation ---\nprint(\"\\nEstimating pose...\")\npose_estimator = PoseEstimator(static_image_mode=True, model_complexity=2)\nlandmarks, raw_result = pose_estimator.process_frame(frame)\n\nif landmarks is None:\n    pose_estimator.close()\n    raise ValueError(\"No pose detected in image. Make sure the player is clearly visible.\")\n\npixel_lm = pose_estimator.get_pixel_landmarks(raw_result, frame.shape)\npose_estimator.close()\nprint(\"  Pose detected successfully!\")\n\n# --- Get contact point ---\ncontact_point = landmarks.get(contact_wrist_name, np.zeros(3))\npelvis = landmarks.get(\"pelvis\", np.zeros(3))\n\n# --- Transform coordinates ---\ncentered = pelvis_origin_transform(landmarks)\nground_z = estimate_ground_plane(centered)\nadjusted = apply_ground_plane(centered, ground_z)\n\n# Contact point in same coordinate system\ncontact_adjusted = contact_point - pelvis - np.array([0, 0, ground_z])\n\n# --- Compute measurements ---\nprint(\"Computing measurements...\")\nmeas = compute_measurements(adjusted, contact_adjusted)\nmeas[\"contact_wrist\"] = contact_wrist_name\nmeas[\"shot_type\"] = SHOT_TYPE\n\n# --- Create output directory ---\noutput_dir = \"/content/output\"\nos.makedirs(output_dir, exist_ok=True)\n\n# --- 1. Annotated frame with FULL skeleton ---\nprint(\"\\n\" + \"=\"*60)\nprint(\"POSE VERIFICATION - Check that skeleton matches your body\")\nprint(\"=\"*60)\n\nannotated = frame.copy()\nannotated = draw_skeleton(annotated, pixel_lm, thickness=3)\n\n# Draw contact wrist with larger red marker\nif contact_wrist_name in pixel_lm:\n    cx, cy = pixel_lm[contact_wrist_name]\n    draw_contact_point(annotated, cx, cy, radius=15)\n\n# Add label for contact point\nif contact_wrist_name in pixel_lm:\n    cx, cy = pixel_lm[contact_wrist_name]\n    cv2.putText(annotated, f\"CONTACT ({hand_label})\", (cx + 20, cy - 10),\n                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n\nout_skeleton_path = os.path.join(output_dir, f\"skeleton_{os.path.splitext(image_filename)[0]}.png\")\nsave_annotated_frame(annotated, out_skeleton_path)\n\nprint(\"\\nSkeleton overlay (verify joints are correctly placed):\")\ndisplay(IPImage(filename=out_skeleton_path, width=800))\n\n# --- 2. 3D Pose Visualization ---\nprint(\"\\n\" + \"=\"*60)\nprint(\"3D POSE VIEW - Verify depth estimation\")\nprint(\"=\"*60)\n\nfig = plt.figure(figsize=(12, 5))\n\n# 3D scatter of landmarks\nax1 = fig.add_subplot(121, projection='3d')\nax1.set_title(\"3D Pose (pelvis-centered)\")\n\n# Plot each landmark\ncolors = {\n    'pelvis': 'black', 'left_hip': 'green', 'right_hip': 'green',\n    'left_shoulder': 'blue', 'right_shoulder': 'blue',\n    'left_elbow': 'cyan', 'right_elbow': 'cyan',\n    'left_wrist': 'magenta', 'right_wrist': 'magenta',\n    'left_knee': 'orange', 'right_knee': 'orange',\n    'left_ankle': 'brown', 'right_ankle': 'brown',\n    'nose': 'red', 'head': 'red'\n}\n\nfor name, coords in adjusted.items():\n    if name in colors:\n        c = colors[name]\n        # MediaPipe: x=lateral, y=vertical (neg=up), z=depth (neg=forward)\n        ax1.scatter(coords[0]*100, -coords[2]*100, -coords[1]*100,\n                   c=c, s=50, label=name)\n        ax1.text(coords[0]*100, -coords[2]*100, -coords[1]*100, name, fontsize=7)\n\n# Mark contact point\ncx, cy, cz = contact_adjusted\nax1.scatter(cx*100, -cz*100, -cy*100, c='red', s=200, marker='*', label='CONTACT')\n\nax1.set_xlabel('Lateral (cm)')\nax1.set_ylabel('Forward (cm)')\nax1.set_zlabel('Height (cm)')\n\n# Top-down view (bird's eye)\nax2 = fig.add_subplot(122)\nax2.set_title(\"Top-down view (bird's eye)\")\nax2.set_aspect('equal')\n\nfor name, coords in adjusted.items():\n    if name in colors:\n        c = colors[name]\n        ax2.scatter(coords[0]*100, -coords[2]*100, c=c, s=50)\n        ax2.annotate(name, (coords[0]*100, -coords[2]*100), fontsize=7)\n\nax2.scatter(cx*100, -cz*100, c='red', s=200, marker='*')\nax2.annotate('CONTACT', (cx*100, -cz*100), fontsize=9, color='red')\nax2.set_xlabel('Lateral (cm) ← Left | Right →')\nax2.set_ylabel('Forward (cm) ↑')\nax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\nax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nout_3d_path = os.path.join(output_dir, f\"pose_3d_{os.path.splitext(image_filename)[0]}.png\")\nplt.savefig(out_3d_path, dpi=120)\nplt.close()\n\ndisplay(IPImage(filename=out_3d_path, width=900))\n\n# --- 3. Measurements ---\nprint(\"\\n\" + \"=\"*60)\nprint(\"CONTACT POINT MEASUREMENTS\")\nprint(\"=\"*60)\nprint(f\"\\nShot type: {SHOT_TYPE}\")\nprint(f\"Contact wrist: {hand_label}\")\nprint()\nprint(f\"Lateral offset:      {meas.get('lateral_offset_cm', 0):>7.1f} cm  ({meas.get('lateral_offset_inches', 0):>5.1f} in)\")\nprint(f\"  (+ = to your left, - = to your right)\")\nprint(f\"Forward/back:        {meas.get('forward_back_cm', 0):>7.1f} cm  ({meas.get('forward_back_inches', 0):>5.1f} in)\")\nprint(f\"  (+ = in front, - = behind)\")\nprint(f\"Height above ground: {meas.get('height_above_ground_cm', 0):>7.1f} cm  ({meas.get('height_above_ground_inches', 0):>5.1f} in)\")\nif \"shoulder_line_distance_cm\" in meas:\n    print(f\"Shoulder line dist:  {meas.get('shoulder_line_distance_cm', 0):>7.1f} cm  ({meas.get('shoulder_line_distance_inches', 0):>5.1f} in)\")\nif \"relative_to_shoulder_height_cm\" in meas:\n    print(f\"vs Shoulder height:  {meas.get('relative_to_shoulder_height_cm', 0):>7.1f} cm  ({meas.get('relative_to_shoulder_height_inches', 0):>5.1f} in)\")\n    print(f\"  (+ = above shoulder, - = below)\")\nprint(\"=\"*60)\n\n# Save CSV\ncsv_path = os.path.join(output_dir, f\"measurements_{os.path.splitext(image_filename)[0]}.csv\")\ndf = pd.DataFrame([meas])\ndf.to_csv(csv_path, index=False)\nprint(f\"\\nResults saved to {output_dir}/\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 3. Download Results\nfrom google.colab import files as colab_files\nimport glob\n\noutput_dir = \"/content/output\"\npng_files = glob.glob(os.path.join(output_dir, \"contact_analyzed_*.png\"))\ncsv_files = glob.glob(os.path.join(output_dir, \"measurements_*.csv\"))\n\nprint(\"Downloading files...\")\nfor f in png_files + csv_files:\n    print(f\"  {os.path.basename(f)}\")\n    colab_files.download(f)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}