{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis Contact Point Analysis\n",
    "\n",
    "Upload a **video** of your tennis rally to automatically detect contact frames and analyze body positioning.\n",
    "\n",
    "**How it works:**\n",
    "1. **TrackNet** (deep learning) tracks the ball throughout the video\n",
    "2. **Audio analysis** detects impact sounds (ball hitting racket)\n",
    "3. Both signals are **fused** for robust contact detection\n",
    "4. For each contact, we analyze pose and measure contact point spacing\n",
    "\n",
    "**Cells:**\n",
    "1. **Setup** - Install dependencies\n",
    "2. **Upload & Detect** - Upload video and run contact detection\n",
    "3. **Generate Diagnostic Video** - Creates video with overlays showing detection signals\n",
    "4. **Text Diagnostics** - Frame-by-frame text output\n",
    "5. **Analyze Contact** - Detailed analysis of a selected contact\n",
    "6. **Batch Analysis** - Analyze all contacts at once\n",
    "7. **Download** - Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Setup - Install Dependencies\n",
    "import os, sys, shutil\n",
    "\n",
    "REPO_URL = \"https://github.com/xiaoxiang-ma/tennis_contact_point_spacing.git\"\n",
    "REPO_DIR = \"/content/tennis_contact_point_spacing\"\n",
    "\n",
    "# Always re-clone to ensure latest code\n",
    "if os.path.exists(REPO_DIR):\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "!git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "!pip install -q -r {REPO_DIR}/requirements.txt\n",
    "\n",
    "# Clear any cached module imports from previous runs\n",
    "for mod_name in list(sys.modules.keys()):\n",
    "    if mod_name.startswith((\"src.\", \"utils.\")):\n",
    "        del sys.modules[mod_name]\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "# Create weights directory\n",
    "os.makedirs(os.path.join(REPO_DIR, \"weights\"), exist_ok=True)\n",
    "\n",
    "print(\"\\nSetup complete!\")\n",
    "print(\"Note: TrackNet weights will be downloaded automatically on first use (~50MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. Upload Video & Detect Contacts\n",
    "import numpy as np\n",
    "import cv2\n",
    "from google.colab import files\n",
    "from IPython.display import display, Image as IPImage, HTML\n",
    "import os\n",
    "\n",
    "from utils.video_io import load_video\n",
    "from src.tracknet import TrackNetDetector\n",
    "from src.contact_detection import detect_contacts, get_contact_ball_position\n",
    "\n",
    "#@markdown ### Settings\n",
    "SHOT_TYPE = \"right_forehand\"  #@param [\"right_forehand\", \"right_backhand\", \"left_forehand\", \"left_backhand\"]\n",
    "USE_AUDIO = True  #@param {type:\"boolean\"}\n",
    "DEBUG_MODE = True  #@param {type:\"boolean\"}\n",
    "SAVE_DEBUG_FRAMES = False  #@param {type:\"boolean\"}\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"/content/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Upload video ---\n",
    "print(\"Upload your tennis video (MP4, MOV, etc.):\")\n",
    "uploaded = files.upload()\n",
    "video_filename = list(uploaded.keys())[0]\n",
    "video_path = os.path.join(\"/content\", video_filename)\n",
    "with open(video_path, \"wb\") as f:\n",
    "    f.write(uploaded[video_filename])\n",
    "\n",
    "# --- Load video ---\n",
    "print(f\"\\nLoading video: {video_filename}\")\n",
    "frames, metadata = load_video(video_path)\n",
    "fps = metadata[\"fps\"]\n",
    "print(f\"  Resolution: {metadata['width']}x{metadata['height']}\")\n",
    "print(f\"  Frame rate: {fps:.1f} fps\")\n",
    "print(f\"  Duration: {metadata['duration_sec']:.2f}s ({len(frames)} frames)\")\n",
    "\n",
    "# --- Initialize TrackNet ---\n",
    "print(\"\\nInitializing TrackNet (downloading weights if needed)...\")\n",
    "tracknet = TrackNetDetector(\n",
    "    weights_path=None,  # Auto-download\n",
    "    device=None,  # Auto-detect GPU/CPU\n",
    "    confidence_threshold=0.5,\n",
    "    save_debug_frames=SAVE_DEBUG_FRAMES,\n",
    "    debug_output_dir=os.path.join(output_dir, \"tracknet_debug\"),\n",
    ")\n",
    "\n",
    "# Check if weights loaded successfully\n",
    "if not tracknet.weights_loaded:\n",
    "    print(\"\\n\" + \"!\"*60)\n",
    "    print(\"WARNING: TrackNet weights failed to load!\")\n",
    "    print(\"Ball detection will NOT work properly.\")\n",
    "    print(\"Check the error message above for details.\")\n",
    "    print(\"!\"*60 + \"\\n\")\n",
    "\n",
    "# --- Detect contacts ---\n",
    "print(\"\\nDetecting contacts (this may take a few minutes)...\")\n",
    "contacts, ball_detections = detect_contacts(\n",
    "    video_path=video_path,\n",
    "    frames=frames,\n",
    "    fps=fps,\n",
    "    tracknet_detector=tracknet,\n",
    "    use_audio=USE_AUDIO,\n",
    "    debug=DEBUG_MODE,\n",
    "    save_debug_frames=SAVE_DEBUG_FRAMES,\n",
    ")\n",
    "\n",
    "# --- Build trajectory for diagnostics ---\n",
    "trajectory = tracknet.get_ball_trajectory(ball_detections)\n",
    "\n",
    "# --- Display results ---\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"CONTACT DETECTION RESULTS\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"Ball detected in {len(ball_detections)}/{len(frames)} frames ({100*len(ball_detections)/len(frames):.1f}%)\")\n",
    "\n",
    "print(f\"\\nDetected {len(contacts)} contact(s):\")\n",
    "print()\n",
    "\n",
    "# Store contact info for later use\n",
    "contact_info = []\n",
    "for i, (frame_num, confidence, source) in enumerate(contacts):\n",
    "    time_sec = frame_num / fps\n",
    "    ball_pos, ball_method = get_contact_ball_position(frame_num, ball_detections)\n",
    "    \n",
    "    contact_info.append({\n",
    "        'index': i,\n",
    "        'frame': frame_num,\n",
    "        'time': time_sec,\n",
    "        'confidence': confidence,\n",
    "        'source': source,\n",
    "        'ball_pos': ball_pos,\n",
    "        'ball_method': ball_method,\n",
    "    })\n",
    "    \n",
    "    print(f\"  Contact {i+1}: Frame {frame_num} ({time_sec:.2f}s)\")\n",
    "    print(f\"    Confidence: {confidence:.0%} (source: {source})\")\n",
    "    if ball_pos:\n",
    "        print(f\"    Ball position: ({ball_pos[0]:.0f}, {ball_pos[1]:.0f}) [{ball_method}]\")\n",
    "    else:\n",
    "        print(f\"    Ball position: Not available\")\n",
    "    print()\n",
    "\n",
    "# Store for next cells\n",
    "ANALYSIS_DATA = {\n",
    "    'frames': frames,\n",
    "    'fps': fps,\n",
    "    'metadata': metadata,\n",
    "    'contacts': contact_info,\n",
    "    'contacts_raw': contacts,  # Keep raw format for video generation\n",
    "    'ball_detections': ball_detections,\n",
    "    'trajectory': trajectory,\n",
    "    'shot_type': SHOT_TYPE,\n",
    "    'video_path': video_path,\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Next: Run the DIAGNOSTIC VIDEO cell to visualize detection\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Generate Diagnostic Video (Recommended)\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "from google.colab import files as colab_files\n",
    "\n",
    "from src.visualization import create_diagnostic_video\n",
    "\n",
    "#@markdown ### Settings\n",
    "#@markdown Set the known real contact frame (if you know it) to highlight in yellow:\n",
    "KNOWN_CONTACT_FRAME = 81  #@param {type:\"integer\"}\n",
    "SHOW_TRAJECTORY_TRAIL = True  #@param {type:\"boolean\"}\n",
    "TRAJECTORY_TAIL_FRAMES = 30  #@param {type:\"integer\"}\n",
    "\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first!\")\n",
    "\n",
    "output_dir = \"/content/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_dir, \"diagnostic_video.mp4\")\n",
    "\n",
    "print(\"Generating diagnostic video with overlays...\")\n",
    "print(\"  - Ball position (green circle)\")\n",
    "print(\"  - Velocity vector (yellow arrow)\")\n",
    "print(\"  - Detection signals: SPIKE (cyan), REVERSAL (magenta), DECEL (orange)\")\n",
    "print(\"  - Confidence meter\")\n",
    "print(\"  - Detected contacts (red border)\")\n",
    "if KNOWN_CONTACT_FRAME:\n",
    "    print(f\"  - Known contact frame {KNOWN_CONTACT_FRAME} (yellow border)\")\n",
    "print()\n",
    "\n",
    "create_diagnostic_video(\n",
    "    frames=ANALYSIS_DATA['frames'],\n",
    "    ball_detections=ANALYSIS_DATA['ball_detections'],\n",
    "    contacts=ANALYSIS_DATA['contacts_raw'],\n",
    "    fps=ANALYSIS_DATA['fps'],\n",
    "    output_path=output_path,\n",
    "    known_contact_frame=KNOWN_CONTACT_FRAME if KNOWN_CONTACT_FRAME > 0 else None,\n",
    "    show_trajectory=SHOW_TRAJECTORY_TRAIL,\n",
    "    trajectory_tail=TRAJECTORY_TAIL_FRAMES,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VIDEO OVERLAY LEGEND\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "TOP-LEFT PANEL:\n",
    "  Frame/Time     - Current frame number and timestamp\n",
    "  Ball           - DETECTED (green) or MISSING (red)\n",
    "  Speed          - Current ball speed in px/s\n",
    "  Signal boxes   - SPIKE (cyan), REVERSAL (magenta), DECEL (orange)\n",
    "  Conf bar       - Detection confidence (green=high, yellow=medium, orange=low)\n",
    "\n",
    "ON FRAME:\n",
    "  Green circle   - Ball position (size = confidence)\n",
    "  Yellow arrow   - Velocity direction\n",
    "  Green trail    - Recent ball trajectory\n",
    "  RED border     - Frame detected as contact\n",
    "  YELLOW border  - Known real contact frame (for comparison)\n",
    "\"\"\")\n",
    "\n",
    "# Display video in notebook\n",
    "from base64 import b64encode\n",
    "video_data = open(output_path, 'rb').read()\n",
    "video_b64 = b64encode(video_data).decode()\n",
    "display(HTML(f'''\n",
    "<video width=\"800\" controls>\n",
    "  <source src=\"data:video/mp4;base64,{video_b64}\" type=\"video/mp4\">\n",
    "</video>\n",
    "'''))\n",
    "\n",
    "print(f\"\\nVideo saved to: {output_path}\")\n",
    "print(\"Downloading...\")\n",
    "colab_files.download(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Text Diagnostics - Frame-by-Frame Analysis (Optional)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from src.contact_detection import compute_ball_velocity, debug_frame_region\n",
    "\n",
    "#@markdown ### Diagnostic Settings\n",
    "KNOWN_CONTACT_FRAME = 81  #@param {type:\"integer\"}\n",
    "SHOW_ALL_FRAMES = False  #@param {type:\"boolean\"}\n",
    "FOCUS_WINDOW = 15  #@param {type:\"integer\"}\n",
    "\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first!\")\n",
    "\n",
    "ball_detections = ANALYSIS_DATA['ball_detections']\n",
    "trajectory = ANALYSIS_DATA['trajectory']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "num_frames = len(ANALYSIS_DATA['frames'])\n",
    "\n",
    "# Compute velocities\n",
    "velocities = compute_ball_velocity(trajectory, fps)\n",
    "vel_dict = {v[0]: {'vx': v[1], 'vy': v[2], 'speed': v[3]} for v in velocities}\n",
    "\n",
    "# Reference speed for spike detection\n",
    "speeds = np.array([v[3] for v in velocities])\n",
    "nonzero_speeds = speeds[speeds > 1e-3]\n",
    "ref_speed = np.median(nonzero_speeds) if len(nonzero_speeds) > 0 else 100\n",
    "spike_threshold = ref_speed * 2.0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DIAGNOSTIC: FRAME-BY-FRAME CONTACT DETECTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nVideo: {num_frames} frames at {fps:.1f} fps\")\n",
    "print(f\"Ball detected in: {len(ball_detections)} frames ({100*len(ball_detections)/num_frames:.1f}%)\")\n",
    "print(f\"Velocity samples: {len(velocities)}\")\n",
    "print(f\"\\nReference speed (median): {ref_speed:.1f} px/s\")\n",
    "print(f\"Spike threshold (2x median): {spike_threshold:.1f} px/s\")\n",
    "\n",
    "# Find detection gaps\n",
    "detected_frames = set(ball_detections.keys())\n",
    "if detected_frames:\n",
    "    min_f, max_f = min(detected_frames), max(detected_frames)\n",
    "    gaps = []\n",
    "    gap_start = None\n",
    "    for f in range(min_f, max_f + 1):\n",
    "        if f not in detected_frames:\n",
    "            if gap_start is None:\n",
    "                gap_start = f\n",
    "        else:\n",
    "            if gap_start is not None:\n",
    "                gap_len = f - gap_start\n",
    "                if gap_len >= 3:\n",
    "                    gaps.append((gap_start, f - 1, gap_len))\n",
    "                gap_start = None\n",
    "    if gap_start is not None:\n",
    "        gaps.append((gap_start, max_f, max_f - gap_start + 1))\n",
    "    \n",
    "    if gaps:\n",
    "        print(f\"\\n\" + \"-\"*40)\n",
    "        print(\"DETECTION GAPS (3+ consecutive missing frames):\")\n",
    "        print(\"-\"*40)\n",
    "        for start, end, length in gaps:\n",
    "            contains_known = start <= KNOWN_CONTACT_FRAME <= end\n",
    "            marker = \" <<<< KNOWN CONTACT IN THIS GAP!\" if contains_known else \"\"\n",
    "            print(f\"  Frames {start:3d}-{end:3d}: {length} frames missing{marker}\")\n",
    "\n",
    "# Build frame-by-frame data\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"FRAME-BY-FRAME VELOCITY ANALYSIS\")\n",
    "if not SHOW_ALL_FRAMES:\n",
    "    print(f\"(Showing frames {KNOWN_CONTACT_FRAME - FOCUS_WINDOW} to {KNOWN_CONTACT_FRAME + FOCUS_WINDOW})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Frame':>6} {'Time':>7} {'Ball?':>6} {'Speed':>10} {'Vx':>8} {'Vy':>8} {'Spike':>7} {'Reversal':>9} {'Decel':>7} {'Conf':>6} {'Notes'}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Determine frame range\n",
    "if SHOW_ALL_FRAMES:\n",
    "    frame_range = range(num_frames)\n",
    "else:\n",
    "    frame_range = range(\n",
    "        max(0, KNOWN_CONTACT_FRAME - FOCUS_WINDOW),\n",
    "        min(num_frames, KNOWN_CONTACT_FRAME + FOCUS_WINDOW + 1)\n",
    "    )\n",
    "\n",
    "rows = []\n",
    "prev_vel = None\n",
    "\n",
    "for f in frame_range:\n",
    "    time_sec = f / fps\n",
    "    \n",
    "    # Ball detection status\n",
    "    ball_detected = f in ball_detections\n",
    "    ball_str = \"YES\" if ball_detected else \"---\"\n",
    "    \n",
    "    # Velocity data\n",
    "    if f in vel_dict:\n",
    "        v = vel_dict[f]\n",
    "        speed = v['speed']\n",
    "        vx, vy = v['vx'], v['vy']\n",
    "        speed_str = f\"{speed:8.1f}\"\n",
    "        vx_str = f\"{vx:+7.1f}\"\n",
    "        vy_str = f\"{vy:+7.1f}\"\n",
    "        \n",
    "        # Spike detection\n",
    "        is_spike = speed > spike_threshold\n",
    "        spike_str = f\"{speed/ref_speed:.1f}x\" if is_spike else \"\"\n",
    "        \n",
    "        # Reversal detection (need previous velocity)\n",
    "        reversal_str = \"\"\n",
    "        reversal_val = 0\n",
    "        if prev_vel is not None:\n",
    "            dot = prev_vel['vx'] * vx + prev_vel['vy'] * vy\n",
    "            if dot < 0:\n",
    "                mag0 = np.sqrt(prev_vel['vx']**2 + prev_vel['vy']**2)\n",
    "                mag1 = np.sqrt(vx**2 + vy**2)\n",
    "                cos_angle = dot / (mag0 * mag1 + 1e-6)\n",
    "                reversal_val = max(0, -cos_angle)\n",
    "                reversal_str = f\"{reversal_val:.2f}\"\n",
    "        \n",
    "        # Deceleration detection\n",
    "        decel_str = \"\"\n",
    "        decel_val = 0\n",
    "        if prev_vel is not None:\n",
    "            prev_speed = prev_vel['speed']\n",
    "            if prev_speed > ref_speed and speed < prev_speed * 0.5:\n",
    "                decel_val = 1 - (speed / prev_speed)\n",
    "                decel_str = f\"{decel_val:.2f}\"\n",
    "        \n",
    "        # Compute confidence\n",
    "        conf = 0.0\n",
    "        if reversal_val > 0:\n",
    "            conf += 0.3 * (0.5 + 0.5 * reversal_val)\n",
    "        if is_spike:\n",
    "            conf += 0.2 * min((speed / ref_speed) / 2.0, 1.5)\n",
    "        if decel_val > 0:\n",
    "            conf += 0.2 * decel_val\n",
    "        conf = min(conf, 0.7)\n",
    "        conf_str = f\"{conf:.2f}\" if conf > 0.1 else \"\"\n",
    "        \n",
    "        prev_vel = v\n",
    "    else:\n",
    "        speed_str = \"---\"\n",
    "        vx_str = \"---\"\n",
    "        vy_str = \"---\"\n",
    "        spike_str = \"\"\n",
    "        reversal_str = \"\"\n",
    "        decel_str = \"\"\n",
    "        conf_str = \"\"\n",
    "        conf = 0\n",
    "        is_spike = False\n",
    "    \n",
    "    # Notes\n",
    "    notes = []\n",
    "    if f == KNOWN_CONTACT_FRAME:\n",
    "        notes.append(\"<<< KNOWN CONTACT\")\n",
    "    if any(c['frame'] == f for c in contacts):\n",
    "        c = next(c for c in contacts if c['frame'] == f)\n",
    "        notes.append(f\"DETECTED (conf={c['confidence']:.2f})\")\n",
    "    if not ball_detected and f > 0 and (f-1) in ball_detections:\n",
    "        notes.append(\"ball lost\")\n",
    "    if ball_detected and f > 0 and (f-1) not in ball_detections:\n",
    "        notes.append(\"ball found\")\n",
    "    \n",
    "    notes_str = \" | \".join(notes)\n",
    "    \n",
    "    # Highlight important rows\n",
    "    marker = \">>>\" if f == KNOWN_CONTACT_FRAME else \"   \"\n",
    "    \n",
    "    print(f\"{marker}{f:3d} {time_sec:7.2f}s {ball_str:>6} {speed_str:>10} {vx_str:>8} {vy_str:>8} {spike_str:>7} {reversal_str:>9} {decel_str:>7} {conf_str:>6}  {notes_str}\")\n",
    "\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nKnown contact frame: {KNOWN_CONTACT_FRAME}\")\n",
    "print(f\"  Ball detected at frame {KNOWN_CONTACT_FRAME}? {KNOWN_CONTACT_FRAME in ball_detections}\")\n",
    "print(f\"  Velocity data at frame {KNOWN_CONTACT_FRAME}? {KNOWN_CONTACT_FRAME in vel_dict}\")\n",
    "\n",
    "# Was it detected?\n",
    "detected_at_known = any(c['frame'] == KNOWN_CONTACT_FRAME for c in contacts)\n",
    "if detected_at_known:\n",
    "    print(f\"  Contact WAS detected at frame {KNOWN_CONTACT_FRAME}\")\n",
    "else:\n",
    "    # Find closest detection\n",
    "    if contacts:\n",
    "        closest = min(contacts, key=lambda c: abs(c['frame'] - KNOWN_CONTACT_FRAME))\n",
    "        print(f\"  Contact NOT detected at frame {KNOWN_CONTACT_FRAME}\")\n",
    "        print(f\"  Closest detection: frame {closest['frame']} ({abs(closest['frame'] - KNOWN_CONTACT_FRAME)} frames away)\")\n",
    "    else:\n",
    "        print(f\"  No contacts detected at all!\")\n",
    "\n",
    "# Check if frame is in a gap\n",
    "in_gap = KNOWN_CONTACT_FRAME not in ball_detections\n",
    "if in_gap:\n",
    "    print(f\"\\n  ** FRAME {KNOWN_CONTACT_FRAME} IS MISSING BALL DETECTION **\")\n",
    "    print(f\"     This is likely why the contact was not detected.\")\n",
    "    print(f\"     The ball is probably occluded by the racket at contact.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Analyze Selected Contact\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from IPython.display import display, Image as IPImage\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "\n",
    "from utils.coordinate_transforms import (\n",
    "    pelvis_origin_transform, estimate_ground_plane, apply_ground_plane\n",
    ")\n",
    "from src.pose_estimation import PoseEstimator\n",
    "from src.measurements import compute_measurements\n",
    "from src.visualization import (\n",
    "    draw_skeleton, draw_contact_point, save_annotated_frame\n",
    ")\n",
    "\n",
    "#@markdown ### Select which contact to analyze:\n",
    "CONTACT_INDEX = 0  #@param {type:\"integer\"}\n",
    "\n",
    "# Validate\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first to detect contacts!\")\n",
    "\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "if len(contacts) == 0:\n",
    "    raise ValueError(\"No contacts were detected in the video.\")\n",
    "\n",
    "if CONTACT_INDEX < 0 or CONTACT_INDEX >= len(contacts):\n",
    "    raise ValueError(f\"Invalid contact index. Valid range: 0-{len(contacts)-1}\")\n",
    "\n",
    "contact = contacts[CONTACT_INDEX]\n",
    "frame_num = contact['frame']\n",
    "ball_pos = contact['ball_pos']\n",
    "ball_method = contact['ball_method']\n",
    "shot_type = ANALYSIS_DATA['shot_type']\n",
    "frames = ANALYSIS_DATA['frames']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "\n",
    "print(f\"Analyzing Contact {CONTACT_INDEX + 1}\")\n",
    "print(f\"  Frame: {frame_num} ({contact['time']:.2f}s)\")\n",
    "print(f\"  Detection confidence: {contact['confidence']:.0%}\")\n",
    "print(f\"  Ball position method: {ball_method}\")\n",
    "\n",
    "# Get frame\n",
    "frame = frames[frame_num]\n",
    "h, w = frame.shape[:2]\n",
    "\n",
    "# Determine which wrist to use based on shot type\n",
    "if shot_type in [\"right_forehand\", \"right_backhand\"]:\n",
    "    contact_wrist_name = \"right_wrist\"\n",
    "    hand_label = \"RIGHT\"\n",
    "else:\n",
    "    contact_wrist_name = \"left_wrist\"\n",
    "    hand_label = \"LEFT\"\n",
    "\n",
    "# --- Pose estimation ---\n",
    "print(\"\\nEstimating pose...\")\n",
    "pose_estimator = PoseEstimator(static_image_mode=True, model_complexity=2)\n",
    "landmarks, raw_result = pose_estimator.process_frame(frame)\n",
    "\n",
    "if landmarks is None:\n",
    "    pose_estimator.close()\n",
    "    raise ValueError(\"No pose detected in frame. The player may not be clearly visible.\")\n",
    "\n",
    "pixel_lm = pose_estimator.get_pixel_landmarks(raw_result, frame.shape)\n",
    "pose_estimator.close()\n",
    "print(\"  Pose detected successfully!\")\n",
    "\n",
    "# --- Get contact point (ball position or fallback to wrist) ---\n",
    "if ball_pos is not None:\n",
    "    contact_pixel = ball_pos\n",
    "    contact_source = f\"ball ({ball_method})\"\n",
    "    print(f\"  Using ball position as contact point: ({ball_pos[0]:.0f}, {ball_pos[1]:.0f})\")\n",
    "else:\n",
    "    # Fallback to wrist\n",
    "    if contact_wrist_name in pixel_lm:\n",
    "        contact_pixel = pixel_lm[contact_wrist_name]\n",
    "        contact_source = \"wrist (fallback)\"\n",
    "        print(f\"  Ball not detected - using wrist position as fallback\")\n",
    "    else:\n",
    "        raise ValueError(\"Neither ball nor wrist position available\")\n",
    "\n",
    "# --- Transform coordinates for measurements ---\n",
    "pelvis = landmarks.get(\"pelvis\", np.zeros(3))\n",
    "centered = pelvis_origin_transform(landmarks)\n",
    "ground_z = estimate_ground_plane(centered)\n",
    "adjusted = apply_ground_plane(centered, ground_z)\n",
    "\n",
    "# For contact point, we need to estimate 3D position from 2D ball detection\n",
    "# Use wrist depth as approximation (ball is near wrist at contact)\n",
    "wrist_3d = landmarks.get(contact_wrist_name, np.zeros(3))\n",
    "contact_3d = wrist_3d.copy()  # Start with wrist position\n",
    "\n",
    "# If we have ball pixel position, adjust x/y based on pixel offset from wrist\n",
    "if ball_pos is not None and contact_wrist_name in pixel_lm:\n",
    "    wrist_px = pixel_lm[contact_wrist_name]\n",
    "    # Estimate scale from wrist (pixels to normalized coords)\n",
    "    # This is approximate - proper depth estimation would need stereo or depth camera\n",
    "    px_offset_x = ball_pos[0] - wrist_px[0]\n",
    "    px_offset_y = ball_pos[1] - wrist_px[1]\n",
    "    \n",
    "    # Rough scaling (assume ~1000px corresponds to ~1 normalized unit)\n",
    "    scale = 0.001  \n",
    "    contact_3d[0] += px_offset_x * scale\n",
    "    contact_3d[1] += px_offset_y * scale\n",
    "\n",
    "contact_adjusted = contact_3d - pelvis - np.array([0, 0, ground_z])\n",
    "\n",
    "# --- Compute measurements ---\n",
    "print(\"Computing measurements...\")\n",
    "meas = compute_measurements(adjusted, contact_adjusted)\n",
    "meas[\"contact_source\"] = contact_source\n",
    "meas[\"ball_detection_method\"] = ball_method\n",
    "meas[\"shot_type\"] = shot_type\n",
    "meas[\"frame_num\"] = frame_num\n",
    "meas[\"contact_confidence\"] = contact['confidence']\n",
    "\n",
    "# --- Create output directory ---\n",
    "output_dir = \"/content/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- 1. Annotated frame with skeleton + contact point ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONTACT FRAME ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "annotated = frame.copy()\n",
    "annotated = draw_skeleton(annotated, pixel_lm, thickness=3)\n",
    "\n",
    "# Draw contact point (ball position or wrist)\n",
    "cx, cy = int(contact_pixel[0]), int(contact_pixel[1])\n",
    "draw_contact_point(annotated, cx, cy, radius=15)\n",
    "\n",
    "# Add label\n",
    "label = f\"CONTACT ({contact_source})\"\n",
    "cv2.putText(annotated, label, (cx + 20, cy - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "# Add frame info\n",
    "info_text = f\"Frame {frame_num} | {contact['time']:.2f}s | Conf: {contact['confidence']:.0%}\"\n",
    "cv2.putText(annotated, info_text, (20, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "out_path = os.path.join(output_dir, f\"contact_{CONTACT_INDEX+1}_frame_{frame_num}.png\")\n",
    "save_annotated_frame(annotated, out_path)\n",
    "\n",
    "print(\"\\nAnnotated contact frame:\")\n",
    "display(IPImage(filename=out_path, width=800))\n",
    "\n",
    "# --- 2. Measurements ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONTACT POINT MEASUREMENTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nShot type: {shot_type}\")\n",
    "print(f\"Contact source: {contact_source}\")\n",
    "print()\n",
    "print(f\"Lateral offset:      {meas.get('lateral_offset_cm', 0):>7.1f} cm  ({meas.get('lateral_offset_inches', 0):>5.1f} in)\")\n",
    "print(f\"  (+ = to your left, - = to your right)\")\n",
    "print(f\"Forward/back:        {meas.get('forward_back_cm', 0):>7.1f} cm  ({meas.get('forward_back_inches', 0):>5.1f} in)\")\n",
    "print(f\"  (+ = in front, - = behind)\")\n",
    "print(f\"Height above ground: {meas.get('height_above_ground_cm', 0):>7.1f} cm  ({meas.get('height_above_ground_inches', 0):>5.1f} in)\")\n",
    "if \"shoulder_line_distance_cm\" in meas:\n",
    "    print(f\"Shoulder line dist:  {meas.get('shoulder_line_distance_cm', 0):>7.1f} cm  ({meas.get('shoulder_line_distance_inches', 0):>5.1f} in)\")\n",
    "if \"relative_to_shoulder_height_cm\" in meas:\n",
    "    print(f\"vs Shoulder height:  {meas.get('relative_to_shoulder_height_cm', 0):>7.1f} cm  ({meas.get('relative_to_shoulder_height_inches', 0):>5.1f} in)\")\n",
    "    print(f\"  (+ = above shoulder, - = below)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save measurements CSV\n",
    "csv_path = os.path.join(output_dir, f\"measurements_contact_{CONTACT_INDEX+1}.csv\")\n",
    "df = pd.DataFrame([meas])\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nMeasurements saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6. Batch Analysis - Analyze All Contacts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils.coordinate_transforms import (\n",
    "    pelvis_origin_transform, estimate_ground_plane, apply_ground_plane\n",
    ")\n",
    "from src.pose_estimation import PoseEstimator\n",
    "from src.measurements import compute_measurements\n",
    "\n",
    "#@markdown Run this cell to analyze ALL detected contacts at once.\n",
    "\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first!\")\n",
    "\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "frames = ANALYSIS_DATA['frames']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "shot_type = ANALYSIS_DATA['shot_type']\n",
    "ball_detections = ANALYSIS_DATA['ball_detections']\n",
    "\n",
    "if len(contacts) == 0:\n",
    "    print(\"No contacts to analyze.\")\n",
    "else:\n",
    "    print(f\"Analyzing {len(contacts)} contacts...\\n\")\n",
    "    \n",
    "    all_measurements = []\n",
    "    pose_estimator = PoseEstimator(static_image_mode=True, model_complexity=2)\n",
    "    \n",
    "    # Determine wrist based on shot type\n",
    "    if shot_type in [\"right_forehand\", \"right_backhand\"]:\n",
    "        contact_wrist_name = \"right_wrist\"\n",
    "    else:\n",
    "        contact_wrist_name = \"left_wrist\"\n",
    "    \n",
    "    for contact in contacts:\n",
    "        idx = contact['index']\n",
    "        frame_num = contact['frame']\n",
    "        ball_pos = contact['ball_pos']\n",
    "        ball_method = contact['ball_method']\n",
    "        \n",
    "        print(f\"Contact {idx+1}: Frame {frame_num}...\", end=\" \")\n",
    "        \n",
    "        frame = frames[frame_num]\n",
    "        landmarks, raw_result = pose_estimator.process_frame(frame)\n",
    "        \n",
    "        if landmarks is None:\n",
    "            print(\"SKIPPED (no pose detected)\")\n",
    "            continue\n",
    "        \n",
    "        pixel_lm = pose_estimator.get_pixel_landmarks(raw_result, frame.shape)\n",
    "        \n",
    "        # Get contact point\n",
    "        if ball_pos is not None:\n",
    "            contact_pixel = ball_pos\n",
    "            contact_source = f\"ball ({ball_method})\"\n",
    "        elif contact_wrist_name in pixel_lm:\n",
    "            contact_pixel = pixel_lm[contact_wrist_name]\n",
    "            contact_source = \"wrist (fallback)\"\n",
    "        else:\n",
    "            print(\"SKIPPED (no contact point)\")\n",
    "            continue\n",
    "        \n",
    "        # Transform and measure\n",
    "        pelvis = landmarks.get(\"pelvis\", np.zeros(3))\n",
    "        centered = pelvis_origin_transform(landmarks)\n",
    "        ground_z = estimate_ground_plane(centered)\n",
    "        adjusted = apply_ground_plane(centered, ground_z)\n",
    "        \n",
    "        wrist_3d = landmarks.get(contact_wrist_name, np.zeros(3))\n",
    "        contact_3d = wrist_3d.copy()\n",
    "        \n",
    "        if ball_pos is not None and contact_wrist_name in pixel_lm:\n",
    "            wrist_px = pixel_lm[contact_wrist_name]\n",
    "            px_offset_x = ball_pos[0] - wrist_px[0]\n",
    "            px_offset_y = ball_pos[1] - wrist_px[1]\n",
    "            scale = 0.001\n",
    "            contact_3d[0] += px_offset_x * scale\n",
    "            contact_3d[1] += px_offset_y * scale\n",
    "        \n",
    "        contact_adjusted = contact_3d - pelvis - np.array([0, 0, ground_z])\n",
    "        meas = compute_measurements(adjusted, contact_adjusted)\n",
    "        \n",
    "        meas[\"contact_index\"] = idx + 1\n",
    "        meas[\"frame_num\"] = frame_num\n",
    "        meas[\"time_sec\"] = contact['time']\n",
    "        meas[\"contact_confidence\"] = contact['confidence']\n",
    "        meas[\"contact_source\"] = contact_source\n",
    "        meas[\"detection_source\"] = contact['source']\n",
    "        meas[\"shot_type\"] = shot_type\n",
    "        \n",
    "        all_measurements.append(meas)\n",
    "        print(\"OK\")\n",
    "    \n",
    "    pose_estimator.close()\n",
    "    \n",
    "    # Save combined results\n",
    "    if all_measurements:\n",
    "        output_dir = \"/content/output\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        df = pd.DataFrame(all_measurements)\n",
    "        csv_path = os.path.join(output_dir, \"all_contacts_measurements.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"SUMMARY OF ALL CONTACTS\")\n",
    "        print(\"=\"*60)\n",
    "        display(df[['contact_index', 'frame_num', 'time_sec', 'contact_confidence', \n",
    "                    'lateral_offset_cm', 'forward_back_cm', 'height_above_ground_cm',\n",
    "                    'contact_source']])\n",
    "        \n",
    "        print(f\"\\nResults saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7. Download All Results\n",
    "from google.colab import files as colab_files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "output_dir = \"/content/output\"\n",
    "all_files = glob.glob(os.path.join(output_dir, \"*\"))\n",
    "\n",
    "print(\"Files available for download:\")\n",
    "for f in all_files:\n",
    "    size_mb = os.path.getsize(f) / (1024 * 1024)\n",
    "    print(f\"  {os.path.basename(f)} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(\"\\nDownloading...\")\n",
    "for f in all_files:\n",
    "    colab_files.download(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
