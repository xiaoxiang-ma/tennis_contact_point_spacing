{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis Contact Point Analysis - MVP\n",
    "\n",
    "Upload a tennis rally video to detect contact points, estimate 3D pose, and measure contact position relative to body landmarks.\n",
    "\n",
    "**Steps:**\n",
    "1. Run the **Setup** cell to install dependencies\n",
    "2. Run the **Upload & Process** cell to upload your video and run the pipeline\n",
    "3. View results and download annotated images + CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 1. Setup - Install dependencies and clone repo\nimport os, sys, shutil\n\nREPO_URL = \"https://github.com/xiaoxiang-ma/tennis_contact_point_spacing.git\"\nREPO_DIR = \"/content/tennis_contact_point_spacing\"\n\n# Always re-clone to ensure latest code\nif os.path.exists(REPO_DIR):\n    shutil.rmtree(REPO_DIR)\n!git clone {REPO_URL} {REPO_DIR}\n\n!pip install -q -r {REPO_DIR}/requirements.txt\n\n# Clear any cached module imports from previous runs\nfor mod_name in list(sys.modules.keys()):\n    if mod_name.startswith((\"src.\", \"utils.\")):\n        del sys.modules[mod_name]\n\nif REPO_DIR not in sys.path:\n    sys.path.insert(0, REPO_DIR)\n\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Upload & Process Video\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom google.colab import files\nfrom tqdm.notebook import tqdm\nfrom IPython.display import display, Image as IPImage\nimport os\n\nfrom utils.video_io import load_video\nfrom utils.coordinate_transforms import (\n    pelvis_origin_transform, estimate_ground_plane,\n    apply_ground_plane, estimate_player_height_scale\n)\nfrom src.ball_detection import BallTracker\nfrom src.pose_estimation import PoseEstimator, LANDMARK_MAP\nfrom src.contact_detection import detect_contacts\nfrom src.measurements import compute_measurements\nfrom src.visualization import (\n    annotate_contact_frame, save_annotated_frame\n)\n\n# --- Upload video ---\nprint(\"Upload your tennis video (MP4, MOV, AVI):\")\nuploaded = files.upload()\nvideo_filename = list(uploaded.keys())[0]\nvideo_path = os.path.join(\"/content\", video_filename)\nwith open(video_path, \"wb\") as f:\n    f.write(uploaded[video_filename])\n\n# --- Load video ---\nprint(f\"\\nLoading video: {video_filename}\")\nframes, meta = load_video(video_path)\nfps = meta[\"fps\"]\nprint(f\"  {len(frames)} frames, {meta['width']}x{meta['height']}, {fps:.1f} fps, {meta['duration_sec']:.1f}s\")\n\n# --- Ball detection ---\nprint(\"\\nDetecting ball...\")\ntracker = BallTracker()  # HSV fallback (no TrackNet weights)\nball_detections = tracker.detect_all(frames, progress=True)\nprint(f\"  Ball detected in {len(ball_detections)}/{len(frames)} frames\")\n\n# Quick diagnostic: show ball position range\nif ball_detections:\n    xs = [d[1] for d in ball_detections]\n    ys = [d[2] for d in ball_detections]\n    print(f\"  Ball x range: {min(xs):.0f}-{max(xs):.0f}, y range: {min(ys):.0f}-{max(ys):.0f}\")\n\n# --- Pose estimation ---\nprint(\"\\nEstimating pose...\")\npose_estimator = PoseEstimator(static_image_mode=True, model_complexity=2)\n\nwrist_positions = {}  # frame_num -> (x, y) in pixels\npose_cache = {}  # frame_num -> (world_landmarks, raw_result)\n\n# Process ALL frames (short video, and we need full wrist trajectory)\nfor i in tqdm(range(len(frames)), desc=\"Pose estimation\"):\n    landmarks, result = pose_estimator.process_frame(frames[i])\n    if landmarks is not None:\n        pose_cache[i] = (landmarks, result)\n\n        # Get pixel-space wrist positions for contact detection\n        pixel_lm = pose_estimator.get_pixel_landmarks(result, frames[i].shape)\n        if pixel_lm is not None:\n            h, w = frames[i].shape[:2]\n            rw = pixel_lm.get(\"right_wrist\")\n            lw = pixel_lm.get(\"left_wrist\")\n            if rw and lw:\n                mid_x = w / 2\n                if abs(rw[0] - mid_x) > abs(lw[0] - mid_x):\n                    wrist_positions[i] = (float(rw[0]), float(rw[1]))\n                else:\n                    wrist_positions[i] = (float(lw[0]), float(lw[1]))\n\npose_estimator.close()\nprint(f\"  Pose estimated for {len(pose_cache)} frames\")\nprint(f\"  Wrist positions for {len(wrist_positions)} frames\")\n\n# --- Contact detection ---\nprint(\"\\nDetecting contacts...\")\ncontacts = detect_contacts(\n    ball_detections, fps,\n    wrist_positions=wrist_positions,\n    velocity_spike_threshold=1.5,\n    wrist_proximity_px=300,\n    min_frame_gap=int(fps * 0.3),  # at least 0.3s apart\n    debug=True,\n)\nprint(f\"  Found {len(contacts)} contact(s)\")\n\nif not contacts:\n    print(\"\\nNo contacts detected. Try adjusting camera angle or lighting.\")\n\n# --- Process each contact ---\noutput_dir = \"/content/output\"\nos.makedirs(output_dir, exist_ok=True)\n\nall_measurements = []\n\n# Create a fresh pose estimator for any missing contact frames\npe2 = PoseEstimator(static_image_mode=True, model_complexity=2)\n\nfor contact_frame, confidence in contacts:\n    if contact_frame not in pose_cache:\n        landmarks, result = pe2.process_frame(frames[contact_frame])\n        if landmarks is None:\n            print(f\"  Frame {contact_frame}: no pose detected, skipping\")\n            continue\n        pose_cache[contact_frame] = (landmarks, result)\n\n    landmarks, raw_result = pose_cache[contact_frame]\n\n    # Determine dominant wrist (the one further extended from pelvis)\n    lw = landmarks.get(\"left_wrist\", np.zeros(3))\n    rw = landmarks.get(\"right_wrist\", np.zeros(3))\n    pelvis = landmarks.get(\"pelvis\", np.zeros(3))\n    if np.linalg.norm(rw - pelvis) > np.linalg.norm(lw - pelvis):\n        contact_wrist_name = \"right_wrist\"\n        contact_point = rw\n    else:\n        contact_wrist_name = \"left_wrist\"\n        contact_point = lw\n\n    # Transform to pelvis-centered, ground-adjusted coordinates\n    centered = pelvis_origin_transform(landmarks)\n    ground_z = estimate_ground_plane(centered)\n    adjusted = apply_ground_plane(centered, ground_z)\n\n    # Contact point in same coordinate system\n    contact_adjusted = contact_point - pelvis - np.array([0, 0, ground_z])\n\n    # Compute measurements\n    meas = compute_measurements(adjusted, contact_adjusted)\n    meas[\"frame_number\"] = contact_frame\n    meas[\"timestamp\"] = contact_frame / fps\n    meas[\"confidence\"] = confidence\n    meas[\"contact_x\"] = contact_point[0]\n    meas[\"contact_y\"] = contact_point[1]\n    meas[\"contact_z\"] = contact_point[2]\n    all_measurements.append(meas)\n\n    # Visualize\n    pixel_lm = pe2.get_pixel_landmarks(raw_result, frames[contact_frame].shape)\n    if pixel_lm is None:\n        # Fallback: re-run pose just for pixel landmarks\n        _, r2 = pe2.process_frame(frames[contact_frame])\n        pixel_lm = pe2.get_pixel_landmarks(r2, frames[contact_frame].shape)\n\n    if pixel_lm:\n        annotated = annotate_contact_frame(\n            frames[contact_frame], pixel_lm, contact_wrist_name,\n            meas, contact_frame, fps\n        )\n        out_path = os.path.join(output_dir, f\"contact_frame_{contact_frame}.png\")\n        save_annotated_frame(annotated, out_path)\n    print(f\"  Contact at frame {contact_frame} (t={contact_frame/fps:.2f}s, conf={confidence:.2f})\")\n\npe2.close()\n\n# Save CSV\nif all_measurements:\n    video_stem = os.path.splitext(video_filename)[0]\n    csv_path = os.path.join(output_dir, f\"measurements_{video_stem}.csv\")\n    df = pd.DataFrame(all_measurements)\n    first_cols = [\"frame_number\", \"timestamp\", \"confidence\",\n                  \"contact_x\", \"contact_y\", \"contact_z\"]\n    other_cols = [c for c in df.columns if c not in first_cols]\n    df = df[first_cols + sorted(other_cols)]\n    df.to_csv(csv_path, index=False)\n    print(f\"\\nMeasurements saved to {csv_path}\")\n\nprint(\"\\nProcessing complete!\")"
  },
  {
   "cell_type": "code",
   "source": "#@title 2b. Visual Debug — Wrist speed, ball detections, sample frames\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.use(\"Agg\")\nfrom IPython.display import display, Image as IPImage\n\n# --- Compute wrist speed for plotting ---\nsorted_wf = sorted(wrist_positions.keys())\nwrist_speed_frames = []\nwrist_speed_vals = []\nfor i in range(1, len(sorted_wf)):\n    f0, f1 = sorted_wf[i-1], sorted_wf[i]\n    dt = (f1 - f0) / fps\n    if dt <= 0:\n        continue\n    x0, y0 = wrist_positions[f0]\n    x1, y1 = wrist_positions[f1]\n    speed = np.sqrt((x1-x0)**2 + (y1-y0)**2) / dt\n    wrist_speed_frames.append(f1)\n    wrist_speed_vals.append(speed)\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Top-left: Wrist speed over time (PRIMARY signal)\naxes[0, 0].plot(wrist_speed_frames, wrist_speed_vals, 'b.-', markersize=2)\naxes[0, 0].set_title(\"Wrist speed over time (px/s) — PRIMARY contact signal\")\naxes[0, 0].set_xlabel(\"Frame\")\naxes[0, 0].set_ylabel(\"Speed (px/s)\")\nif wrist_speed_vals:\n    p85 = np.percentile(wrist_speed_vals, 85)\n    axes[0, 0].axhline(y=p85, color='orange', linestyle=':', label=f'p85 threshold: {p85:.0f}')\nfor cf, cc in contacts:\n    axes[0, 0].axvline(x=cf, color='red', alpha=0.8, linestyle='--', label=f'contact {cf}')\naxes[0, 0].legend(fontsize=8)\n\n# Top-right: Wrist X and Y position\naxes[0, 1].plot(sorted_wf, [wrist_positions[f][0] for f in sorted_wf], 'b.-', markersize=2, label='wrist x')\naxes[0, 1].plot(sorted_wf, [wrist_positions[f][1] for f in sorted_wf], 'c.-', markersize=2, label='wrist y')\nfor cf, cc in contacts:\n    axes[0, 1].axvline(x=cf, color='red', alpha=0.8, linestyle='--')\naxes[0, 1].set_title(\"Wrist position over time\")\naxes[0, 1].set_xlabel(\"Frame\")\naxes[0, 1].set_ylabel(\"Pixels\")\naxes[0, 1].legend()\n\n# Bottom-left: Ball detection positions (for reference, may be wrong)\nball_frames_list = [d[0] for d in ball_detections]\nball_xs = [d[1] for d in ball_detections]\nball_ys = [d[2] for d in ball_detections]\naxes[1, 0].plot(ball_frames_list, ball_xs, 'g.-', markersize=2, label='HSV \"ball\" x')\naxes[1, 0].plot(ball_frames_list, ball_ys, 'y.-', markersize=2, label='HSV \"ball\" y')\naxes[1, 0].set_title(\"HSV ball detection (may be wrong object)\")\naxes[1, 0].set_xlabel(\"Frame\")\naxes[1, 0].set_ylabel(\"Pixels\")\naxes[1, 0].legend()\n\n# Bottom-right: empty or summary text\naxes[1, 1].axis(\"off\")\nsummary = f\"Video: {len(frames)} frames, {fps:.0f} fps, {len(frames)/fps:.1f}s\\n\"\nsummary += f\"Pose detected: {len(pose_cache)}/{len(frames)} frames\\n\"\nsummary += f\"Wrist tracked: {len(wrist_positions)} frames\\n\"\nsummary += f\"Contacts found: {len(contacts)}\\n\"\nfor cf, cc in contacts:\n    summary += f\"  Frame {cf} (t={cf/fps:.2f}s, conf={cc:.2f})\\n\"\naxes[1, 1].text(0.1, 0.5, summary, fontsize=12, family='monospace',\n                verticalalignment='center', transform=axes[1, 1].transAxes)\n\nplt.tight_layout()\nplt.savefig(\"/content/output/debug_plots.png\", dpi=120)\nplt.close()\ndisplay(IPImage(filename=\"/content/output/debug_plots.png\", width=900))\n\n# --- Annotated sample frames showing wrist (blue) and contact frames (red) ---\nprint(\"\\nSample frames with wrist position (blue) and contacts (red border):\")\ncontact_frame_set = set(cf for cf, _ in contacts)\n\n# Show evenly spaced frames + all contact frames\nsample_indices = set(np.linspace(0, len(frames) - 1, 6, dtype=int).tolist())\nsample_indices.update(contact_frame_set)\nsample_indices = sorted(sample_indices)[:8]\n\nncols = min(4, len(sample_indices))\nnrows = (len(sample_indices) + ncols - 1) // ncols\nfig2, axes2 = plt.subplots(nrows, ncols, figsize=(5 * ncols, 5 * nrows))\nif nrows == 1 and ncols == 1:\n    axes2 = np.array([axes2])\naxes2 = axes2.flat\n\nfor i, (idx, ax) in enumerate(zip(sample_indices, axes2)):\n    frame_rgb = cv2.cvtColor(frames[idx], cv2.COLOR_BGR2RGB).copy()\n\n    # Draw wrist position\n    if idx in wrist_positions:\n        wx, wy = int(wrist_positions[idx][0]), int(wrist_positions[idx][1])\n        cv2.circle(frame_rgb, (wx, wy), 12, (50, 50, 255), 3)\n        cv2.putText(frame_rgb, \"wrist\", (wx + 15, wy - 5),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 255), 2)\n\n    title = f\"Frame {idx} (t={idx/fps:.2f}s)\"\n    if idx in contact_frame_set:\n        # Red border for contact frames\n        cv2.rectangle(frame_rgb, (0, 0), (frame_rgb.shape[1]-1, frame_rgb.shape[0]-1),\n                      (255, 0, 0), 6)\n        title += \" *** CONTACT ***\"\n\n    ax.imshow(frame_rgb)\n    ax.set_title(title, fontsize=10, color='red' if idx in contact_frame_set else 'black')\n    ax.axis(\"off\")\n\nfor i in range(len(sample_indices), nrows * ncols):\n    axes2[i].axis(\"off\")\n\nplt.tight_layout()\nplt.savefig(\"/content/output/debug_frames.png\", dpi=120)\nplt.close()\ndisplay(IPImage(filename=\"/content/output/debug_frames.png\", width=900))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Results - View annotated frames & download\n",
    "import glob\n",
    "from IPython.display import display, Image as IPImage, HTML\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = \"/content/output\"\n",
    "\n",
    "# Display annotated images\n",
    "png_files = sorted(glob.glob(os.path.join(output_dir, \"contact_frame_*.png\")))\n",
    "if png_files:\n",
    "    print(f\"Found {len(png_files)} contact frame(s):\\n\")\n",
    "    for png_path in png_files:\n",
    "        print(os.path.basename(png_path))\n",
    "        display(IPImage(filename=png_path, width=800))\n",
    "        print()\n",
    "else:\n",
    "    print(\"No annotated frames found.\")\n",
    "\n",
    "# Display measurements table\n",
    "csv_files = glob.glob(os.path.join(output_dir, \"measurements_*.csv\"))\n",
    "if csv_files:\n",
    "    df = pd.read_csv(csv_files[0])\n",
    "    print(\"\\nMeasurements:\")\n",
    "    display(df)\n",
    "\n",
    "# Download links\n",
    "print(\"\\n--- Download Files ---\")\n",
    "from google.colab import files as colab_files\n",
    "for f in png_files + csv_files:\n",
    "    colab_files.download(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}