{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis Contact Point Analysis - MVP\n",
    "\n",
    "Upload a tennis rally video to detect contact points, estimate 3D pose, and measure contact position relative to body landmarks.\n",
    "\n",
    "**Steps:**\n",
    "1. Run the **Setup** cell to install dependencies\n",
    "2. Run the **Upload & Process** cell to upload your video and run the pipeline\n",
    "3. View results and download annotated images + CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 1. Setup - Install dependencies and clone repo\nimport os, sys, shutil\n\nREPO_URL = \"https://github.com/xiaoxiang-ma/tennis_contact_point_spacing.git\"\nREPO_DIR = \"/content/tennis_contact_point_spacing\"\n\n# Always re-clone to ensure latest code\nif os.path.exists(REPO_DIR):\n    shutil.rmtree(REPO_DIR)\n!git clone {REPO_URL} {REPO_DIR}\n\n!pip install -q -r {REPO_DIR}/requirements.txt\n\n# Clear any cached module imports from previous runs\nfor mod_name in list(sys.modules.keys()):\n    if mod_name.startswith((\"src.\", \"utils.\")):\n        del sys.modules[mod_name]\n\nif REPO_DIR not in sys.path:\n    sys.path.insert(0, REPO_DIR)\n\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Upload & Process Video\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom google.colab import files\nfrom tqdm.notebook import tqdm\nfrom IPython.display import display, Image as IPImage\nimport os\n\nfrom utils.video_io import load_video\nfrom utils.coordinate_transforms import (\n    pelvis_origin_transform, estimate_ground_plane,\n    apply_ground_plane, estimate_player_height_scale\n)\nfrom src.ball_detection import BallTracker\nfrom src.pose_estimation import PoseEstimator, LANDMARK_MAP\nfrom src.contact_detection import detect_contacts\nfrom src.measurements import compute_measurements\nfrom src.visualization import (\n    annotate_contact_frame, save_annotated_frame\n)\n\n# --- Upload video ---\nprint(\"Upload your tennis video (MP4, MOV, AVI):\")\nuploaded = files.upload()\nvideo_filename = list(uploaded.keys())[0]\nvideo_path = os.path.join(\"/content\", video_filename)\nwith open(video_path, \"wb\") as f:\n    f.write(uploaded[video_filename])\n\n# --- Load video ---\nprint(f\"\\nLoading video: {video_filename}\")\nframes, meta = load_video(video_path)\nfps = meta[\"fps\"]\nprint(f\"  {len(frames)} frames, {meta['width']}x{meta['height']}, {fps:.1f} fps, {meta['duration_sec']:.1f}s\")\n\n# --- Ball detection ---\nprint(\"\\nDetecting ball...\")\ntracker = BallTracker()  # HSV fallback (no TrackNet weights)\nball_detections = tracker.detect_all(frames, progress=True)\nprint(f\"  Ball detected in {len(ball_detections)}/{len(frames)} frames\")\n\n# --- Pose estimation ---\nprint(\"\\nEstimating pose...\")\npose_estimator = PoseEstimator(static_image_mode=True, model_complexity=2)\n\nwrist_positions = {}  # frame_num -> (x, y) in pixels\npose_cache = {}  # frame_num -> (world_landmarks, raw_result)\n\n# Only process frames near ball detections + some padding\nball_frames = set(d[0] for d in ball_detections)\nframes_to_process = set()\nfor bf in ball_frames:\n    for offset in range(-5, 6):\n        f = bf + offset\n        if 0 <= f < len(frames):\n            frames_to_process.add(f)\n\nfor i in tqdm(sorted(frames_to_process), desc=\"Pose estimation\"):\n    landmarks, result = pose_estimator.process_frame(frames[i])\n    if landmarks is not None:\n        pose_cache[i] = (landmarks, result)\n\n        # Get pixel-space wrist positions for contact detection\n        pixel_lm = pose_estimator.get_pixel_landmarks(result, frames[i].shape)\n        if pixel_lm is not None:\n            h, w = frames[i].shape[:2]\n            rw = pixel_lm.get(\"right_wrist\")\n            lw = pixel_lm.get(\"left_wrist\")\n            if rw and lw:\n                mid_x = w / 2\n                if abs(rw[0] - mid_x) > abs(lw[0] - mid_x):\n                    wrist_positions[i] = (float(rw[0]), float(rw[1]))\n                else:\n                    wrist_positions[i] = (float(lw[0]), float(lw[1]))\n\npose_estimator.close()\nprint(f\"  Pose estimated for {len(pose_cache)} frames\")\n\n# --- Contact detection ---\nprint(\"\\nDetecting contacts...\")\ncontacts = detect_contacts(\n    ball_detections, fps,\n    wrist_positions=wrist_positions,\n    velocity_spike_threshold=1.8,\n    wrist_proximity_px=200,\n    min_frame_gap=int(fps * 0.5)  # at least 0.5s apart\n)\nprint(f\"  Found {len(contacts)} contact(s)\")\n\nif not contacts:\n    print(\"\\nNo contacts detected. Try adjusting camera angle or lighting.\")\n\n# --- Process each contact ---\noutput_dir = \"/content/output\"\nos.makedirs(output_dir, exist_ok=True)\n\nall_measurements = []\n\n# Create a fresh pose estimator for any missing contact frames\npe2 = PoseEstimator(static_image_mode=True, model_complexity=2)\n\nfor contact_frame, confidence in contacts:\n    if contact_frame not in pose_cache:\n        landmarks, result = pe2.process_frame(frames[contact_frame])\n        if landmarks is None:\n            print(f\"  Frame {contact_frame}: no pose detected, skipping\")\n            continue\n        pose_cache[contact_frame] = (landmarks, result)\n\n    landmarks, raw_result = pose_cache[contact_frame]\n\n    # Determine dominant wrist (the one further extended from pelvis)\n    lw = landmarks.get(\"left_wrist\", np.zeros(3))\n    rw = landmarks.get(\"right_wrist\", np.zeros(3))\n    pelvis = landmarks.get(\"pelvis\", np.zeros(3))\n    if np.linalg.norm(rw - pelvis) > np.linalg.norm(lw - pelvis):\n        contact_wrist_name = \"right_wrist\"\n        contact_point = rw\n    else:\n        contact_wrist_name = \"left_wrist\"\n        contact_point = lw\n\n    # Transform to pelvis-centered, ground-adjusted coordinates\n    centered = pelvis_origin_transform(landmarks)\n    ground_z = estimate_ground_plane(centered)\n    adjusted = apply_ground_plane(centered, ground_z)\n\n    # Contact point in same coordinate system\n    contact_adjusted = contact_point - pelvis - np.array([0, 0, ground_z])\n\n    # Compute measurements\n    meas = compute_measurements(adjusted, contact_adjusted)\n    meas[\"frame_number\"] = contact_frame\n    meas[\"timestamp\"] = contact_frame / fps\n    meas[\"confidence\"] = confidence\n    meas[\"contact_x\"] = contact_point[0]\n    meas[\"contact_y\"] = contact_point[1]\n    meas[\"contact_z\"] = contact_point[2]\n    all_measurements.append(meas)\n\n    # Visualize\n    pixel_lm = pe2.get_pixel_landmarks(raw_result, frames[contact_frame].shape)\n    if pixel_lm is None:\n        # Fallback: re-run pose just for pixel landmarks\n        _, r2 = pe2.process_frame(frames[contact_frame])\n        pixel_lm = pe2.get_pixel_landmarks(r2, frames[contact_frame].shape)\n\n    if pixel_lm:\n        annotated = annotate_contact_frame(\n            frames[contact_frame], pixel_lm, contact_wrist_name,\n            meas, contact_frame, fps\n        )\n        out_path = os.path.join(output_dir, f\"contact_frame_{contact_frame}.png\")\n        save_annotated_frame(annotated, out_path)\n    print(f\"  Contact at frame {contact_frame} (t={contact_frame/fps:.2f}s, conf={confidence:.2f})\")\n\npe2.close()\n\n# Save CSV\nif all_measurements:\n    video_stem = os.path.splitext(video_filename)[0]\n    csv_path = os.path.join(output_dir, f\"measurements_{video_stem}.csv\")\n    df = pd.DataFrame(all_measurements)\n    first_cols = [\"frame_number\", \"timestamp\", \"confidence\",\n                  \"contact_x\", \"contact_y\", \"contact_z\"]\n    other_cols = [c for c in df.columns if c not in first_cols]\n    df = df[first_cols + sorted(other_cols)]\n    df.to_csv(csv_path, index=False)\n    print(f\"\\nMeasurements saved to {csv_path}\")\n\nprint(\"\\nProcessing complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Results - View annotated frames & download\n",
    "import glob\n",
    "from IPython.display import display, Image as IPImage, HTML\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = \"/content/output\"\n",
    "\n",
    "# Display annotated images\n",
    "png_files = sorted(glob.glob(os.path.join(output_dir, \"contact_frame_*.png\")))\n",
    "if png_files:\n",
    "    print(f\"Found {len(png_files)} contact frame(s):\\n\")\n",
    "    for png_path in png_files:\n",
    "        print(os.path.basename(png_path))\n",
    "        display(IPImage(filename=png_path, width=800))\n",
    "        print()\n",
    "else:\n",
    "    print(\"No annotated frames found.\")\n",
    "\n",
    "# Display measurements table\n",
    "csv_files = glob.glob(os.path.join(output_dir, \"measurements_*.csv\"))\n",
    "if csv_files:\n",
    "    df = pd.read_csv(csv_files[0])\n",
    "    print(\"\\nMeasurements:\")\n",
    "    display(df)\n",
    "\n",
    "# Download links\n",
    "print(\"\\n--- Download Files ---\")\n",
    "from google.colab import files as colab_files\n",
    "for f in png_files + csv_files:\n",
    "    colab_files.download(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}