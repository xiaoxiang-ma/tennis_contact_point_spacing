{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis Contact Detection by Sound\n",
    "\n",
    "Detect ball-racket contact frames using **pure audio analysis** â€” no visual ball tracking needed.\n",
    "\n",
    "**How it works:**\n",
    "1. Extract audio from your tennis video\n",
    "2. Apply a bandpass filter (1\u20134 kHz) to isolate the characteristic impact \"thump\"\n",
    "3. Compute the amplitude envelope and detect peaks above a noise-adaptive threshold\n",
    "4. Map detected peaks back to video frames\n",
    "5. Display annotated debug frames for visual inspection\n",
    "\n",
    "**Why audio?** Tennis ball impacts produce a sharp, distinctive sound (5\u201320ms duration) in the 1\u20134 kHz frequency range. This is far more reliable than visual ball tracking which fails on blurry/occluded balls.\n",
    "\n",
    "**Cells:**\n",
    "1. **Setup** \u2014 Install dependencies\n",
    "2. **Upload & Detect** \u2014 Upload video, run audio contact detection\n",
    "3. **Audio Debug** \u2014 Waveform and envelope plots with detected peaks\n",
    "4. **Visual Inspection** \u2014 Debug frames showing each detected contact\n",
    "5. **Pose Analysis** \u2014 Analyze body positioning at selected contact (optional)\n",
    "6. **Download** \u2014 Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Setup - Install Dependencies\n",
    "import os, sys, shutil\n",
    "\n",
    "REPO_URL = \"https://github.com/xiaoxiang-ma/tennis_contact_point_spacing.git\"\n",
    "REPO_DIR = \"/content/tennis_contact_point_spacing\"\n",
    "\n",
    "# Always re-clone to ensure latest code\n",
    "if os.path.exists(REPO_DIR):\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "!git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "!pip install -q -r {REPO_DIR}/requirements.txt\n",
    "\n",
    "# Clear any cached module imports from previous runs\n",
    "for mod_name in list(sys.modules.keys()):\n",
    "    if mod_name.startswith((\"src.\", \"utils.\")):\n",
    "        del sys.modules[mod_name]\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "print(\"\\nSetup complete! No GPU required \u2014 audio detection runs on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. Upload Video & Detect Contacts by Sound\n",
    "import numpy as np\n",
    "import cv2\n",
    "from google.colab import files\n",
    "from IPython.display import display, Image as IPImage, HTML\n",
    "import os\n",
    "\n",
    "from utils.video_io import load_video\n",
    "from src.contact_detection import detect_contacts, get_debug_audio_data\n",
    "\n",
    "#@markdown ### Audio Detection Settings\n",
    "#@markdown **Bandpass Filter** \u2014 Tennis impacts are strongest in 1\u20134 kHz\n",
    "LOW_FREQ = 1000  #@param {type:\"integer\"}\n",
    "HIGH_FREQ = 4000  #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown **Sensitivity** \u2014 Lower threshold factor = more sensitive (more detections, more false positives)\n",
    "PEAK_THRESHOLD_FACTOR = 3.0  #@param {type:\"slider\", min:1.5, max:6.0, step:0.5}\n",
    "\n",
    "#@markdown **Noise Floor Percentile** \u2014 Baseline noise level estimation\n",
    "NOISE_PERCENTILE = 75.0  #@param {type:\"slider\", min:50.0, max:95.0, step:5.0}\n",
    "\n",
    "#@markdown **Min Gap Between Contacts (ms)** \u2014 Suppress duplicate detections\n",
    "MIN_GAP_MS = 300  #@param {type:\"slider\", min:100, max:1000, step:50}\n",
    "\n",
    "#@markdown ### Other Settings\n",
    "SAMPLE_RATE = 22050  #@param {type:\"integer\"}\n",
    "DEBUG_MODE = True  #@param {type:\"boolean\"}\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"/content/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Upload video ---\n",
    "print(\"Upload your tennis video (MP4, MOV, etc.):\")\n",
    "uploaded = files.upload()\n",
    "video_filename = list(uploaded.keys())[0]\n",
    "video_path = os.path.join(\"/content\", video_filename)\n",
    "with open(video_path, \"wb\") as f:\n",
    "    f.write(uploaded[video_filename])\n",
    "\n",
    "# --- Load video ---\n",
    "print(f\"\\nLoading video: {video_filename}\")\n",
    "frames, metadata = load_video(video_path)\n",
    "fps = metadata[\"fps\"]\n",
    "print(f\"  Resolution: {metadata['width']}x{metadata['height']}\")\n",
    "print(f\"  Frame rate: {fps:.1f} fps\")\n",
    "print(f\"  Duration: {metadata['duration_sec']:.2f}s ({len(frames)} frames)\")\n",
    "\n",
    "# --- Detect contacts via audio ---\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DETECTING CONTACTS BY SOUND\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "contacts = detect_contacts(\n",
    "    video_path=video_path,\n",
    "    fps=fps,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    low_freq=LOW_FREQ,\n",
    "    high_freq=HIGH_FREQ,\n",
    "    min_gap_ms=MIN_GAP_MS,\n",
    "    noise_percentile=NOISE_PERCENTILE,\n",
    "    peak_threshold_factor=PEAK_THRESHOLD_FACTOR,\n",
    "    debug=DEBUG_MODE,\n",
    ")\n",
    "\n",
    "# --- Get audio debug data for plotting ---\n",
    "audio_data = get_debug_audio_data(\n",
    "    video_path, SAMPLE_RATE, LOW_FREQ, HIGH_FREQ,\n",
    ")\n",
    "\n",
    "# --- Display results ---\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"RESULTS: {len(contacts)} contact(s) detected\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "contact_info = []\n",
    "for i, (frame_num, confidence, source) in enumerate(contacts):\n",
    "    time_sec = frame_num / fps\n",
    "    contact_info.append({\n",
    "        'index': i,\n",
    "        'frame': frame_num,\n",
    "        'time': time_sec,\n",
    "        'confidence': confidence,\n",
    "    })\n",
    "    print(f\"  Contact {i+1}: Frame {frame_num} ({time_sec:.2f}s) \u2014 confidence {confidence:.0%}\")\n",
    "\n",
    "# Store for subsequent cells\n",
    "ANALYSIS_DATA = {\n",
    "    'frames': frames,\n",
    "    'fps': fps,\n",
    "    'metadata': metadata,\n",
    "    'contacts': contact_info,\n",
    "    'contacts_raw': contacts,\n",
    "    'audio_data': audio_data,\n",
    "    'video_path': video_path,\n",
    "}\n",
    "\n",
    "print(f\"\\nNext: Run cell 3 to see the audio waveform, then cell 4 for debug frames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Audio Debug \u2014 Waveform, Envelope & Detected Peaks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first!\")\n",
    "\n",
    "audio_data = ANALYSIS_DATA['audio_data']\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "sr = audio_data['sample_rate']\n",
    "raw_audio = audio_data['raw_audio']\n",
    "envelope = audio_data['envelope']\n",
    "duration = audio_data['duration_sec']\n",
    "\n",
    "# Time axes\n",
    "time_audio = np.arange(len(raw_audio)) / sr\n",
    "time_env = np.arange(len(envelope)) / sr\n",
    "\n",
    "# Noise floor and threshold (match detection logic)\n",
    "noise_floor = np.percentile(envelope, NOISE_PERCENTILE)\n",
    "threshold = noise_floor * PEAK_THRESHOLD_FACTOR\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 10), sharex=True)\n",
    "\n",
    "# --- Raw waveform ---\n",
    "axes[0].plot(time_audio, raw_audio, color='steelblue', linewidth=0.3, alpha=0.7)\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].set_title('Raw Audio Waveform')\n",
    "for c in contacts:\n",
    "    axes[0].axvline(c['time'], color='red', linewidth=1.5, alpha=0.8, linestyle='--')\n",
    "axes[0].set_xlim(0, duration)\n",
    "\n",
    "# --- Filtered envelope ---\n",
    "axes[1].plot(time_env, envelope, color='darkorange', linewidth=0.5)\n",
    "axes[1].axhline(noise_floor, color='gray', linewidth=1, linestyle=':', label=f'Noise floor ({NOISE_PERCENTILE}th pctl)')\n",
    "axes[1].axhline(threshold, color='red', linewidth=1, linestyle='--', label=f'Threshold ({PEAK_THRESHOLD_FACTOR}x noise)')\n",
    "axes[1].set_ylabel('Envelope Amplitude')\n",
    "axes[1].set_title(f'Bandpass Filtered Envelope ({LOW_FREQ}\u2013{HIGH_FREQ} Hz)')\n",
    "axes[1].legend(loc='upper right')\n",
    "for c in contacts:\n",
    "    axes[1].axvline(c['time'], color='red', linewidth=1.5, alpha=0.8, linestyle='--')\n",
    "\n",
    "# --- Zoomed envelope with contact markers ---\n",
    "axes[2].plot(time_env, envelope, color='darkorange', linewidth=0.5)\n",
    "axes[2].axhline(threshold, color='red', linewidth=1, linestyle='--', alpha=0.5)\n",
    "axes[2].set_ylabel('Envelope Amplitude')\n",
    "axes[2].set_xlabel('Time (seconds)')\n",
    "axes[2].set_title('Detected Contacts')\n",
    "\n",
    "for c in contacts:\n",
    "    axes[2].axvline(c['time'], color='red', linewidth=2, alpha=0.9)\n",
    "    axes[2].annotate(\n",
    "        f\"Contact {c['index']+1}\\nFrame {c['frame']}\\n{c['confidence']:.0%}\",\n",
    "        xy=(c['time'], threshold),\n",
    "        xytext=(c['time'] + duration * 0.01, threshold * 1.5),\n",
    "        fontsize=8,\n",
    "        color='red',\n",
    "        fontweight='bold',\n",
    "        arrowprops=dict(arrowstyle='->', color='red', lw=1),\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'audio_debug.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAudio stats:\")\n",
    "print(f\"  Duration: {duration:.2f}s\")\n",
    "print(f\"  Sample rate: {sr} Hz\")\n",
    "print(f\"  Noise floor: {noise_floor:.6f}\")\n",
    "print(f\"  Detection threshold: {threshold:.6f}\")\n",
    "print(f\"  Contacts found: {len(contacts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Visual Inspection \u2014 Debug Frames at Each Contact\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Image as IPImage, HTML\n",
    "\n",
    "from src.visualization import annotate_contact_frame, save_annotated_frame\n",
    "\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first!\")\n",
    "\n",
    "#@markdown ### Display Settings\n",
    "#@markdown **Frames before/after contact** to show for context\n",
    "CONTEXT_FRAMES = 2  #@param {type:\"slider\", min:0, max:5, step:1}\n",
    "\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "frames = ANALYSIS_DATA['frames']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "num_frames = len(frames)\n",
    "\n",
    "if len(contacts) == 0:\n",
    "    print(\"No contacts detected. Try lowering PEAK_THRESHOLD_FACTOR in cell 2.\")\n",
    "else:\n",
    "    print(f\"Showing debug frames for {len(contacts)} detected contact(s)...\")\n",
    "    print(f\"Context: {CONTEXT_FRAMES} frame(s) before and after each contact\\n\")\n",
    "\n",
    "    for c in contacts:\n",
    "        idx = c['index']\n",
    "        frame_num = c['frame']\n",
    "        confidence = c['confidence']\n",
    "        time_sec = c['time']\n",
    "\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"CONTACT {idx+1}: Frame {frame_num} ({time_sec:.2f}s) | Confidence: {confidence:.0%}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        # Collect frames: context before, contact frame, context after\n",
    "        frame_range = range(\n",
    "            max(0, frame_num - CONTEXT_FRAMES),\n",
    "            min(num_frames, frame_num + CONTEXT_FRAMES + 1)\n",
    "        )\n",
    "\n",
    "        row_images = []\n",
    "        for f in frame_range:\n",
    "            img = frames[f].copy()\n",
    "            h, w = img.shape[:2]\n",
    "\n",
    "            if f == frame_num:\n",
    "                # This is the contact frame \u2014 annotate it\n",
    "                img = annotate_contact_frame(img, f, fps, confidence)\n",
    "            else:\n",
    "                # Context frame \u2014 just add frame number\n",
    "                label = f\"Frame {f} ({f/fps:.2f}s)\"\n",
    "                cv2.putText(img, label, (10, 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)\n",
    "\n",
    "            # Resize for display if too large\n",
    "            max_display_h = 300\n",
    "            if h > max_display_h:\n",
    "                scale = max_display_h / h\n",
    "                img = cv2.resize(img, (int(w * scale), max_display_h))\n",
    "\n",
    "            row_images.append(img)\n",
    "\n",
    "        # Concatenate horizontally\n",
    "        # Pad to same height if needed\n",
    "        max_h = max(im.shape[0] for im in row_images)\n",
    "        padded = []\n",
    "        for im in row_images:\n",
    "            if im.shape[0] < max_h:\n",
    "                pad = np.zeros((max_h - im.shape[0], im.shape[1], 3), dtype=np.uint8)\n",
    "                im = np.vstack([im, pad])\n",
    "            padded.append(im)\n",
    "\n",
    "        strip = np.hstack(padded)\n",
    "\n",
    "        # Save and display\n",
    "        strip_path = os.path.join(output_dir, f\"contact_{idx+1}_debug_strip.png\")\n",
    "        save_annotated_frame(strip, strip_path)\n",
    "\n",
    "        # Also save the contact frame alone at full resolution\n",
    "        contact_frame_annotated = annotate_contact_frame(\n",
    "            frames[frame_num].copy(), frame_num, fps, confidence\n",
    "        )\n",
    "        solo_path = os.path.join(output_dir, f\"contact_{idx+1}_frame_{frame_num}.png\")\n",
    "        save_annotated_frame(contact_frame_annotated, solo_path)\n",
    "\n",
    "        # Display strip\n",
    "        _, buf = cv2.imencode('.png', strip)\n",
    "        display(IPImage(data=buf.tobytes(), width=min(strip.shape[1], 1200)))\n",
    "        print()\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Saved {len(contacts)} contact debug strips + full-res frames to {output_dir}\")\n",
    "    print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Pose Analysis at Selected Contact (Optional)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from IPython.display import display, Image as IPImage\n",
    "import os\n",
    "\n",
    "from utils.coordinate_transforms import (\n",
    "    pelvis_origin_transform, estimate_ground_plane, apply_ground_plane\n",
    ")\n",
    "from src.pose_estimation import PoseEstimator\n",
    "from src.measurements import compute_measurements\n",
    "from src.visualization import (\n",
    "    draw_skeleton, draw_contact_point, draw_measurements, save_annotated_frame\n",
    ")\n",
    "\n",
    "#@markdown ### Select contact to analyze\n",
    "CONTACT_INDEX = 0  #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown ### Shot type (determines which wrist = contact point)\n",
    "SHOT_TYPE = \"right_forehand\"  #@param [\"right_forehand\", \"right_backhand\", \"left_forehand\", \"left_backhand\"]\n",
    "\n",
    "if 'ANALYSIS_DATA' not in dir():\n",
    "    raise ValueError(\"Please run cell 2 first!\")\n",
    "\n",
    "contacts = ANALYSIS_DATA['contacts']\n",
    "if len(contacts) == 0:\n",
    "    raise ValueError(\"No contacts detected.\")\n",
    "if CONTACT_INDEX < 0 or CONTACT_INDEX >= len(contacts):\n",
    "    raise ValueError(f\"Invalid index. Valid range: 0-{len(contacts)-1}\")\n",
    "\n",
    "contact = contacts[CONTACT_INDEX]\n",
    "frame_num = contact['frame']\n",
    "frames = ANALYSIS_DATA['frames']\n",
    "fps = ANALYSIS_DATA['fps']\n",
    "\n",
    "contact_wrist_name = \"right_wrist\" if SHOT_TYPE.startswith(\"right\") else \"left_wrist\"\n",
    "\n",
    "print(f\"Analyzing Contact {CONTACT_INDEX + 1}\")\n",
    "print(f\"  Frame: {frame_num} ({contact['time']:.2f}s)\")\n",
    "print(f\"  Confidence: {contact['confidence']:.0%}\")\n",
    "print(f\"  Shot type: {SHOT_TYPE} -> using {contact_wrist_name}\")\n",
    "\n",
    "frame = frames[frame_num]\n",
    "\n",
    "# --- Pose estimation ---\n",
    "print(\"\\nEstimating pose...\")\n",
    "pose_estimator = PoseEstimator(static_image_mode=True, model_complexity=2)\n",
    "landmarks, raw_result = pose_estimator.process_frame(frame)\n",
    "\n",
    "if landmarks is None:\n",
    "    pose_estimator.close()\n",
    "    raise ValueError(\"No pose detected. Player may not be visible in this frame.\")\n",
    "\n",
    "pixel_lm = pose_estimator.get_pixel_landmarks(raw_result, frame.shape)\n",
    "pose_estimator.close()\n",
    "print(\"  Pose detected!\")\n",
    "\n",
    "# --- Contact point = wrist position ---\n",
    "if contact_wrist_name not in pixel_lm:\n",
    "    raise ValueError(f\"{contact_wrist_name} not detected in pose.\")\n",
    "\n",
    "contact_pixel = pixel_lm[contact_wrist_name]\n",
    "\n",
    "# --- Transform coordinates ---\n",
    "centered = pelvis_origin_transform(landmarks)\n",
    "ground_z = estimate_ground_plane(centered)\n",
    "adjusted = apply_ground_plane(centered, ground_z)\n",
    "\n",
    "wrist_3d = landmarks.get(contact_wrist_name, np.zeros(3))\n",
    "pelvis = landmarks.get(\"pelvis\", np.zeros(3))\n",
    "contact_adjusted = wrist_3d - pelvis - np.array([0, 0, ground_z])\n",
    "\n",
    "# --- Measurements ---\n",
    "meas = compute_measurements(adjusted, contact_adjusted)\n",
    "meas[\"shot_type\"] = SHOT_TYPE\n",
    "meas[\"frame_num\"] = frame_num\n",
    "meas[\"contact_confidence\"] = contact['confidence']\n",
    "\n",
    "# --- Annotated frame ---\n",
    "annotated = frame.copy()\n",
    "annotated = draw_skeleton(annotated, pixel_lm, thickness=3)\n",
    "cx, cy = int(contact_pixel[0]), int(contact_pixel[1])\n",
    "draw_contact_point(annotated, cx, cy, radius=15)\n",
    "annotated = draw_measurements(annotated, meas, frame_num, fps)\n",
    "\n",
    "out_path = os.path.join(output_dir, f\"contact_{CONTACT_INDEX+1}_pose.png\")\n",
    "save_annotated_frame(annotated, out_path)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CONTACT POINT MEASUREMENTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Lateral offset:      {meas.get('lateral_offset_cm', 0):>7.1f} cm\")\n",
    "print(f\"Forward/back:        {meas.get('forward_back_cm', 0):>7.1f} cm\")\n",
    "print(f\"Height above ground: {meas.get('height_above_ground_cm', 0):>7.1f} cm\")\n",
    "if 'shoulder_line_distance_cm' in meas:\n",
    "    print(f\"Shoulder distance:   {meas['shoulder_line_distance_cm']:>7.1f} cm\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "display(IPImage(filename=out_path, width=800))\n",
    "\n",
    "csv_path = os.path.join(output_dir, f\"measurements_contact_{CONTACT_INDEX+1}.csv\")\n",
    "pd.DataFrame([meas]).to_csv(csv_path, index=False)\n",
    "print(f\"\\nSaved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6. Download Results\n",
    "from google.colab import files as colab_files\n",
    "import glob\n",
    "import os\n",
    "\n",
    "output_dir = \"/content/output\"\n",
    "all_files = glob.glob(os.path.join(output_dir, \"*\"))\n",
    "\n",
    "if not all_files:\n",
    "    print(\"No output files yet. Run the detection cells first.\")\n",
    "else:\n",
    "    print(\"Files available:\")\n",
    "    for f in sorted(all_files):\n",
    "        size_kb = os.path.getsize(f) / 1024\n",
    "        print(f\"  {os.path.basename(f)} ({size_kb:.1f} KB)\")\n",
    "\n",
    "    print(\"\\nDownloading...\")\n",
    "    for f in all_files:\n",
    "        colab_files.download(f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
